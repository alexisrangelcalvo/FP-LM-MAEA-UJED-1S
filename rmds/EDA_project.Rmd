---
title: "EDA_project"
author: "Alexis Rangel"
date: "2023-04-16"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, cargando Rdata, echo=FALSE}
load("~/Maestria/1er semestre/Modelos lineales/Proyecto final de curso Modelos Lineales MAEA 1er semestre/brief/DatosParaProyecto.RData")
Train_copy = Train
Test_copy = Test
```

```{r, echo=FALSE}
library(tidyverse)
library(explore)
library(tidyr)
library(gridExtra)
library(glue)
library(PerformanceAnalytics)
library(dataxray)
library(correlationfunnel)
library(Amelia)
library(RColorBrewer)
library(paletteer)
```


## Análisis exploratorio

Sobre la base:

La base de datos consta de 18 variable, una variable a predecir y 17 candidatas a predictoras.
34209 registros de cada variable.


1. Loan.Status (VARIABLE DICOTOMA A PREDECIR, VALORES POSIBLES -> [Fully Paid, Charged Off])

Nombre variable | tipo de variable | num valores posibles | valores posibles

2. Term | nominal | 2 | ["Long Term",  "Short Term"]
3. Years.in.current.job | ordinal | 12 | ["n/a", "< 1 year", "1 year":"9 years", "10+ years"]
4. Home.Ownership | nominal | 4 | ["Rent", "Home Mortgage", "Own Home", "HaveMortgage" ]
5. Purpose | nominal | 16 | [...>15 valores posibles...] | << Requiere homologar como factor "other" and "Other" >>
6. Current.Loan.Amount | continua | [min -> 21449.74	, mean -> 14044734.38, max -> 100000002.5]
7. Credit.Score	 | continua | [min -> 584.00, mean -> 1048.48, max -> 7509.0]
8. Annual.Income	| continua | [min -> 164596.55, mean -> 1441110.95, max -> 30838993.9]
9. Monthly.Debt	 | continua | [min -> 0.00, mean -> 19025.56, max -> 229056.4]
10. Years.of.Credit.History	 | continua | [min -> 2.30, mean -> 19.21, max -> 59.6]
11. Months.since.last.delinquent | continua | [min-> 0.00, mean -> 34.96, max -> 178.1]
(Meses desde el último moroso)
12. Number.of.Open.Accounts	 | continua | [min ->  0.00, mean -> 11.43, max -> 49.0]
13. Number.of.Credit.Problems	 | continua | [min -> 0.00, mean -> 0.53, max -> 15.0
]
14. Current.Credit.Balance	| continua | [min ->  0.00, mean -> 259532.60, max -> 7140732.6]
15. Maximum.Open.Credit	| continua | [min ->  0.00, mean -> 666270.83, max -> 798255369.7]
16. Bankruptcies | continua | [min ->  0.00, mean -> 0.46, max -> 7.0]
17. Tax.Liens	 | continua | [min ->  0.00, mean -> 0.42, max -> 14.0]
(gravámenes fiscales)
18. ID ---- excluir variable de cualquier análisis ----

Conteos:
nominal - 3
ordinal - 1
continua - 8

Sobre la variable dependiente y de acuerdo con la siguiente pagina web:

**A charge-off is the opposite of paid in full. It means the lender hasn't received payment for at least 180 days, and the account is in default. The lender, or a third-party collection agency, can still come after this kind of debt. Charge-offs have an extremely negative effect on your credit score.**

Fuente: https://budgeting.thenest.com/account-paid-full-vs-chargeoff-23884.html

#### Objetivos

El presente rmarkdown tiene como objetivo elaborar un análisis exploratorio para el reconocimiento del dataset en la busqueda la lógica del negocio, como de patrones de cumplimiento en las variables a emplear en el modelo de regresión lógistica, así como también proponer limites y filtros a cada variable continua en caso de existir valores presuntamente atipicos. Estas propuestas de filtros se evaluaran y se propondran en el análisis univariado y serán valorados al final del rmarkdown para generar 2 muestras (muestra completa y submuestra 1) con las que en cada una se ajustaran modelos logit, para finalmente comparar los resultados de cada modelo y elegir el de mejor performance contra el estadístico de prueba (% de aciertos).

#### Valores faltantes

```{r, echo=FALSE}
missmap(Train_copy, main = "Missing values vs observed")
```

#### Análisis univariado

<!-- Herramienta Explore -->
<!-- ```{r} -->
<!-- #explore(Train_copy) -->
<!-- ``` -->



- Observamos la distribución desbalanceada de los registros a clásificar, en donde `Fully Paid` representa el 79.23% de la respuesta dicotómica.
```{r, echo=FALSE}
table(Train_copy$Loan.Status)
```


Inicialmente pasamos a binario el pago (`Fully Paid`) o el default (`Charged Off`) con un 1 y un 0 respectivamente.

```{r, echo=FALSE}
Train_copy$Loan.Status = ifelse(Train_copy$Loan.Status  == "Fully Paid", 1, 0)
Train_copy$Loan.Status = as.factor(Train_copy$Loan.Status)
```

- Observamos la variable respuesta `Loan.Status`:
```{r, echo=FALSE}
gg1 = ggplot(Train_copy, aes(fct_infreq(Loan.Status)))+
  geom_bar(stat="count", fill=c("steelblue", "firebrick"))+
  scale_y_continuous(limits = c(0, 30000))+
  labs(title = "Variable 'Loan.Status'",
       x = "Plazo",
       y = "Frecuencia") +
  theme_bw() +
  # Agregar el número de observaciones al filo de cada barra
  geom_text(stat = "count", aes(label = after_stat(format(count, big.mark = ","))), vjust = -0.5)
```

######  Análisis univariado variables nominales y ordinales


<!-- a. Term -->
```{r, echo=FALSE}
#class(Train_copy$Term)
Train_copy$Term = as.factor(Train_copy$Term)

gg2 = ggplot(Train_copy, aes(fct_infreq(Term)))+
  geom_bar(stat="count", fill=c("darkgreen", "yellowgreen"))+
  scale_y_continuous(limits = c(0, 27000))+
  labs(title = "Variable 'Term'",
       x = "Plazo",
       y = "Frecuencia") +
  theme_bw() +
  # Agregar el número de observaciones al filo de cada barra
  geom_text(stat = "count", aes(label = after_stat(format(count, big.mark = ","))), vjust = -0.5)
```

<!-- b. Years.in.current.job -->
```{r, echo=FALSE}
Train_copy$Years.in.current.job = as.factor(Train_copy$Years.in.current.job)
my_palette = paletteer_c("ggthemes::Blue", length(unique(Train_copy$Years.in.current.job)))
my_palette_reverse = rev(my_palette)

gg3 = ggplot(Train_copy, aes(fct_infreq(Years.in.current.job)))+
  geom_bar(stat="count", fill=my_palette_reverse)+
  scale_y_continuous(limits = c(0, 13000))+
  labs(title = "Variable 'Years.in.current.job'",
       x = "Años",
       y = "Frecuencia") +
  theme_bw() +
  # Agregar el número de observaciones al filo de cada barra
  geom_text(stat = "count", aes(label = after_stat(format(count, big.mark = ","))), vjust = -0.5, size = 2)

```

<!-- c. Home.Ownership -->
```{r, echo=FALSE}
Train_copy$Home.Ownership = as.factor(Train_copy$Home.Ownership)

my_palette = paletteer_c("ggthemes::Blue", length(unique(Train_copy$Home.Ownership)))
my_palette_reverse = rev(my_palette)

gg4 = ggplot(Train_copy, aes(fct_infreq(Home.Ownership)))+
  geom_bar(fill=my_palette_reverse)+
  scale_y_continuous(limits = c(0, 20000))+
  labs(title = "Variable 'Home.Ownership'",
       x = "Tipo de dueño",
       y = "Frecuencia") +
  theme_bw() +
  # Agregar el número de observaciones al filo de cada barra
  geom_text(stat = "count", aes(label = after_stat(format(count, big.mark = ","))), vjust = -0.5, size = 3)
```


```{r}
grid.arrange(gg1, gg2, gg3, gg4, nrow = 2)
```



d. Purpose

Por un lado, se unifica el valor de la variable "Other" y "other" en purpose con la funcion tolower(), y por otro, se valorará en el ajuste del modelo la reducción de dimensiones en Train_copy
```{r, echo=FALSE}
#unique(Train_copy$Purpose)
Train_copy$Purpose = tolower(Train_copy$Purpose)

unique(Train_copy$Purpose)
```

```{r, echo=FALSE}
Train_copy$Purpose = as.factor(Train_copy$Purpose)
my_palette = paletteer_c("ggthemes::Blue", length(unique(Train_copy$Purpose)))
my_palette_reverse = rev(my_palette)

ggplot(Train_copy, aes(fct_infreq(Purpose)))+
  geom_bar(stat="count", fill=my_palette_reverse)+
  scale_y_continuous(limits = c(0, 27000))+
  labs(title = "Variable 'Purpose'",
       x = "Proposito",
       y = "Frecuencia") +
  theme_bw() +
  # Agregar el número de observaciones al filo de cada barra
  geom_text(stat = "count", aes(label = after_stat(format(count, big.mark = ","))), size=3, hjust = 0)+
  coord_flip()

#unique(Train_copy$Purpose)
# # Cambiar "hombre" por 1 y "mujer" por 2
# nuevo_vector <- ifelse(observaciones == "hombre", 1, ifelse(observaciones == "mujer", 2, obse
```

```{r, echo=FALSE}
# unique(Train_copy$Purpose)
# Train_copy %>% filter(Purpose == "") %>% select(Purpose, Loan.Status)
```



######  Análisis univariado y agrupación grafica de variables continuas

Para el modelo de regresión logistica se plantean tres escenarios:

- Modelado con toda la muestra.
- Modelado con una muestra reducida (filtro en dos variables continuas)
- Modelado con una muestra aun más reducida (filtro en x variables continuas)

Todos, con su respectivo Train y Test, para la validación cruzada por medio del estadístico PRESS y el Cp de Mallow así como la validación cruzada por k-folds.

Para el modelado con la submuestra, se requiere un análisis estadístico univariado, bivariado y multivariado que complemente la perdida de información. Para esto y dado que son varias variables continuas, probablemente no tenga sentido meter todas en un solo gráfico de boxplot, por lo que buscamos rangos similares para segmentar en 5 grupos para poderapreciar correctamente las distribuciones.


1er grupo de análisis:
`Years.of.Credit.History`, `Number.of.Open.Accounts` y `Months.since.last.delinquent`

```{r, echo=FALSE}
Train_copy_continuas = Train_copy %>% select(Loan.Status, Current.Loan.Amount, Credit.Score, Annual.Income, Monthly.Debt, Years.of.Credit.History, Months.since.last.delinquent, Number.of.Open.Accounts, Current.Credit.Balance, Maximum.Open.Credit, Bankruptcies, Tax.Liens)
```

```{r, echo=FALSE}
train_long_form = gather(select(Train_copy_continuas, -c(Maximum.Open.Credit, Current.Loan.Amount, Annual.Income, Current.Credit.Balance, Monthly.Debt, Credit.Score, Bankruptcies, Tax.Liens)), key = "variable", value = "valor", -Loan.Status)

ggplot(train_long_form, aes(y=variable, x=valor))+
  geom_jitter(aes(alpha=0.1, color=Loan.Status))+
  geom_violin(alpha=0.5)+
  geom_boxplot(width = 0.1, alpha=0.5)+
  stat_summary(fun=mean, colour="darkred", geom="point",
               shape=18, size=3, show.legend=FALSE)+
  scale_x_continuous(NULL)+
  scale_y_discrete(NULL)+
  ggtitle("Violin & Boxplot + jitter por clase (1 = Fully Paid, 0 = Charged Off)")+
  theme_bw()
```

Con la aterior gráfica podemos:
Descartar patrones de cumplimiento por las variables `Years.of.Credit.History`, 
`Number.of.Open.Accounts` y `Months.since.last.delinquent`.
Apreciar la presencia de presuntos valores atípicos en las variables `Years.of.Credit.History`, `Number.of.Open.Accounts` y `Months.since.last.delinquent`.

Para esta variable no se propone ningún filtro de valores presuntamente atípicos.

- Análisis particular de `Years.of.Credit.History`

Visualizamos los cuartiles de la variable `Years.of.Credit.History`


```{r quantiles_, echo=FALSE}
quantiles_ <- function(var){
  vector <- Train_copy_continuas[[var]]
  print("Primer cuartil")
  print(quantile(vector, 0.25))
  #print("-----------")
  print("Segundo cuartil")
  print(quantile(vector, 0.5))
  #print("-----------")
  print("Tercer cuartil")
  print(quantile(vector, 0.75))
  #print("-----------")
  print("Cuarto cuartil")
  print(quantile(vector, 1))
}
```

```{r, echo=FALSE}
quantiles_("Years.of.Credit.History")
```
Destacar que el 75% de los valores del vector Current.Loan.Amount son menores o iguales a 22.7, mientras que el valor máximo es 59.6. El número de observaciones en el 4to cuartil es de 8429, por lo que un filtro eliminando toda esta submuestra nos haría perder una buena parte de la muestra. Por lo que decidimos hacer un análisis más a fondo para encontrar el punto en donde solo filtremos los valores que sean más extremos.

Con el apoyo visual de la siguiente gráfica pudimos decidir filtrar todas aquellas observaciones de la variable Years.of.Credit.History que sean mayores a 40. De esta forma, eliminariamos 401 variables de la muestra, representando un 1.17% de la misma.

```{r, echo=FALSE}
nrow(filter(Train_copy_continuas, Years.of.Credit.History > 40))
```

```{r, echo=FALSE}
plot_1 = ggplot(filter(Train_copy_continuas, Years.of.Credit.History <= 40), aes(y=1, x=Years.of.Credit.History))+
  geom_jitter(aes(color=Loan.Status))+
  geom_violin(alpha=0.5) +
  geom_boxplot(width = 0.1, fill = "white", alpha = 0.5)+
  scale_y_continuous(NULL, labels = NULL)+
  ggtitle("Variable Years.of.Credit.History posterior al filtro (valores < 40)")+
  theme_bw()

plot_2 = ggplot(Train_copy_continuas, aes(y=1, x=Years.of.Credit.History))+
  geom_jitter(aes(color=Loan.Status))+
  geom_violin(alpha=0.5) +
  geom_boxplot(width = 0.1, fill = "white", alpha = 0.5)+
  scale_y_continuous(NULL, labels = NULL)+
  ggtitle("Variable Years.of.Credit.History previo al filtro")+
  theme_bw()

grid.arrange(plot_2, plot_1, ncol = 1)
```
Para esta variable se propone el filtro de valores presuntamente atípicos (Years.of.Credit.History < 40).

- Análisis particular de `Number.of.Open.Accounts`


Visualizamos los cuartiles para `Number.of.Open.Accounts`

```{r}
quantiles_("Number.of.Open.Accounts")
```
Destacar que el 75% de los valores del vector Number.of.Open.Accounts son menores o iguales a 14 cuentas abiertas. El número de observaciones en el 4to cuartil es de 7793, por lo que un filtro eliminando toda esta submuestra nos haría perder una buena parte de la muestra. Por lo que decidimos hacer un análisis más a fondo para encontrar el punto en donde solo filtremos los valores que sean más extremos.

Con el apoyo visual de la siguiente gráfica pudimos decidir filtrar todas aquellas observaciones de la variable Years.of.Credit.History que sean mayores a 30 De esta forma, eliminariamos 152 variables de la muestra, representando un 0.44% de la misma.
```{r, echo=FALSE, include=FALSE}
nrow(filter(Train_copy_continuas, Number.of.Open.Accounts > 30))
```

```{r, echo=FALSE}
plot_1 = ggplot(filter(Train_copy_continuas, Number.of.Open.Accounts <= 30), aes(y=1, x=Number.of.Open.Accounts))+
  geom_jitter(aes(color=Loan.Status))+
  geom_violin(alpha=0.5) +
  geom_boxplot(width = 0.1, fill = "white", alpha = 0.5)+
  scale_y_continuous(NULL, labels = NULL)+
  # scale_x_continuous(breaks = c(0, 200000, 400000, 600000, 800000),
  #                    labels = c("0", "200k", "400k", "600k", "800k"))+
  ggtitle("Variable Number.of.Open.Accounts posterior al filtro (valores < 30)")+
  theme_bw()

plot_2 = ggplot(Train_copy_continuas, aes(y=1, x=Number.of.Open.Accounts))+
  geom_jitter(aes(color=Loan.Status))+
  geom_violin(alpha=0.5) +
  geom_boxplot(width = 0.1, fill = "white", alpha = 0.5)+
  scale_y_continuous(NULL, labels = NULL)+
  # scale_x_continuous(breaks = c(0, 20000000, 40000000, 60000000, 80000000, 100000000),
  #                    labels = c("0", "20M", "40M", "60M", "80M", "100M"))+
  ggtitle("Variable Number.of.Open.Accounts previo al filtro")+
  theme_bw()

grid.arrange(plot_2, plot_1, ncol = 1)
```
De la anterior gráfica podríamos hablar de un patron, en donde podríamos hablar de que si el cliente presenta más de 50 unidades en la variable `Number.of.Open.Accounts`, la probabilidad de `Fully Paid` sería 100%.

Para esta variable se propone el filtro de valores presuntamente atípicos (Years.of.Credit.History < 30).


- `Months.since.last.delinquent`

Visualizamos los cuartiles para `Months.since.last.delinquent`

```{r}
quantiles_("Months.since.last.delinquent")
```
Destacar que el 75% de los valores del vector Months.since.last.delinquent son menores o iguales a 51 meses, mientras que el valor máximo es 178. El número de observaciones en el 4to cuartil es de 8536, por lo que un filtro eliminando toda esta submuestra nos haría perder una buena parte de la muestra. Por lo que decidimos hacer un análisis más a fondo para encontrar el punto en donde solo filtremos los valores que sean más extremos.

Con el apoyo visual de la siguiente gráfica pudimos decidir filtrar todas aquellas observaciones de la variable Months.since.last.delinquent que sean mayores a 51 De esta forma, eliminariamos 31 variables de la muestra, representando un 0.09% de la misma.

```{r, echo=FALSE, include=FALSE}
nrow(filter(Train_copy_continuas, Months.since.last.delinquent > 85))
```

```{r, echo=FALSE}
plot_1 = ggplot(filter(Train_copy_continuas, Months.since.last.delinquent <= 85), aes(y=1, x=Months.since.last.delinquent))+
  geom_jitter(aes(color=Loan.Status))+
  geom_violin(alpha=0.5) +
  geom_boxplot(width = 0.1, fill = "white", alpha = 0.5)+
  scale_y_continuous(NULL, labels = NULL)+
  # scale_x_continuous(breaks = c(0, 200000, 400000, 600000, 800000),
  #                    labels = c("0", "200k", "400k", "600k", "800k"))+
  ggtitle("Variable Months.since.last.delinquent posterior al filtro (valores < 85)")+
  theme_bw()

plot_2 = ggplot(Train_copy_continuas, aes(y=1, x=Months.since.last.delinquent))+
  geom_jitter(aes(color=Loan.Status))+
  geom_violin(alpha=0.5) +
  geom_boxplot(width = 0.1, fill = "white", alpha = 0.5)+
  scale_y_continuous(NULL, labels = NULL)+
  # scale_x_continuous(breaks = c(0, 20000000, 40000000, 60000000, 80000000, 100000000),
  #                    labels = c("0", "20M", "40M", "60M", "80M", "100M"))+
  ggtitle("Variable Months.since.last.delinquent previo al filtro")+
  theme_bw()

grid.arrange(plot_2, plot_1, ncol = 1)
```
Para esta variable se propone el filtro de valores presuntamente atípicos (Years.of.Credit.History < 85).

2do grupo:
`Maximum.Open.Credit` y `Current.Loan.Amount`


```{r, echo=FALSE}
train_selected = select(Train_copy_continuas, Loan.Status, Maximum.Open.Credit, Current.Loan.Amount)
train_long_form1 = gather(train_selected, key = "variable", value = "valor", -Loan.Status)

ggplot(train_long_form1, aes(y=variable, x=valor))+
  geom_jitter(aes(color=Loan.Status))+
  geom_violin(alpha=0.5) +
  # geom_jitter()+
  stat_summary(fun=mean, colour="darkred", geom="point",
               shape=18, size=3, show.legend=FALSE)+
  scale_x_continuous(NULL, breaks = c(0,  100000000, 200000000, 400000000, 600000000, 800000000),
                     labels = c("0", "100M", "200M", "400M","600M", "800M"))+
  scale_y_discrete(NULL)+
  ggtitle("Violin & Boxplot + jitter por clase (1 = Fully Paid, 0 = Charged Off)")+
  theme_bw()
```
Para ambas variables, se vuelve caso de estudio análizar los subgrupos de outliers que se pueden visualizar en la gráfica con la finalidad de evaluar patrones de cumplimiento o la permanencia de estos registros en el ajuste del modelo.

- Análisis particular de la variable `Current.Loan.Amount`

Visualizamos los cuartiles de la variable `Current.Loan.Amount`

```{r, echo=FALSE}
quantiles_("Current.Loan.Amount")
```

En este punto cabe destacar que el 75% de los valores del vector `Current.Loan.Amount` son menores o iguales a 544,016.2. 

Dado que parece que los valores del cuarto cuartil son tan extremos para sugerirnos filtrarlos del estudio, pero en conteo representan 8,551 observaciones, se decide hacer un estudio de la distribución de los datos en el cuarto cuartil para evaluar si se pueden recuperar algunas observaciones. Es claro que un modelo no se va ajustar apropiadamente a registros con valores de cantidad de deuda actual de 500 mil y de 90 millones en una de las variables regresoras, y si se ajusta, no será el mejor modelo o la variable perdera significancia estadística en el modelo. 

En el análisis del cuarto cuartil, que son valores mayores a 544,016.2, se puede observar la siguiente distribución de los datos con ayuda de un gráfico de violin:


```{r, echo=FALSE}
df_temp = filter(Train_copy_continuas, Current.Loan.Amount > 544016.2 )
plot1 = ggplot(df_temp, aes(y=1,x=Current.Loan.Amount))+
  geom_jitter(aes(color=Loan.Status))+
  geom_violin(alpha=0.5) +
  scale_x_continuous(breaks = c(545000, 24500000, 76000000, 90000000),
                     labels = c("0.545M", "24.5M", "76M", "90M"))+
  scale_y_continuous(NULL, labels = NULL)+
  ggtitle("Análisis del 4to cuartil de la variable Current.Loan.Amount (valores > 544,016.2)")+
  theme_bw()


df_temp = filter(Train_copy_continuas, Current.Loan.Amount > 544016.2 )
plot2 = ggplot(df_temp, aes(Current.Loan.Amount))+
  geom_freqpoly()+
  scale_x_continuous(breaks = c(545000, 24500000, 76000000, 90000000),
                     labels = c("0.545M", "24.5M", "76M", "90M"))+
  ggtitle("Análisis del 4to cuartil de la variable Current.Loan.Amount (valores > 544,016.2)")+
  theme_bw()

grid.arrange(plot1, plot2, ncol = 1)
```
Y dado que los valores de la izquierda de la curva bimodal no son tan extremos como los de la parte derecha, nos planteamos la idea de separar la gráfica anterior para un análisis más a fondo. 
Los valores de la curva izquierda bimodal toman la siguiente distribución, con valor mínimo de 544,016.2 y máximo de 24.5 M, como no lo indica la anterior gráfia, que en conteo son 3,839 observaciones y tienen la siguiente distribución. Por su parte, Los valores de la curva derecha bimodal toman la siguiente distribución, con valor mínimo de 50M y máximo de 24l5 M, como no lo indica la anterior gráfia, que en conteo son 4,712 observaciones y tienen la siguiente distribución.
```{r, echo=FALSE}
df_temp = filter(Train_copy_continuas, Current.Loan.Amount > 544016.2 )
df_temp = filter(df_temp, Current.Loan.Amount < 24500000 )

plot_1 = ggplot(df_temp, aes(y=1, x=Current.Loan.Amount))+
  geom_jitter(aes(color=Loan.Status))+
  geom_violin(alpha=0.5) +
  geom_boxplot(width = 0.1, fill = "white", alpha = 0.5)+
  scale_y_continuous(NULL, labels = NULL)+
  scale_x_continuous(breaks = c(550000, 600000, 650000, 700000, 750000, 800000),
                     labels = c("550k", "600k", "650k", "700k", "750k", "800k"))+
  ggtitle("Análisis del 4to cuartil de la variable Current.Loan.Amount (544,016.2 < Valores < 24.5M)")+
  theme_bw()

df_temp = filter(Train_copy_continuas, Current.Loan.Amount > 50000000 )

plot_2 = ggplot(df_temp, aes(y=1, x=Current.Loan.Amount))+
  geom_jitter(aes(color=Loan.Status))+
  geom_violin(alpha=0.5) +
  geom_boxplot(width = 0.1, fill = "white", alpha = 0.5)+
  scale_y_continuous(NULL, labels = NULL)+
  scale_x_continuous(breaks = c(100000000-4, 100000000-2,  100000000, 100000000+2),
                     labels = c("$99,999,996", "$99,999,998", "$100,000,000",
                                "$100,000,002")
                     )+
  scale_color_manual(values = c("turquoise3"))+
  ggtitle("Análisis del 4to cuartil de la variable Current.Loan.Amount (valores > 50M)")+
  theme_bw()

grid.arrange(plot_1, plot_2, ncol = 1)
```

Con la gráfica anterior podríamos afirmar que cualquier registro que tenga un valor mayor a 50M en la variable `Current.Loan.Amount` adoptara un 1 (o `Fully Paid`) en la variable respuesta, por lo que podríamos quitar filtrar dichos registros con estos valores en la muestra para mejorar el ajuste, e incluirlos en un filtro posterior a la predicción del modelo ajustado.

Por lo que en conclusión, en el análisis univariado de la variable `Current.Loan.Amount` y al poder observar la cota superior aproximada a la que debemos delimitarla para restringir valores extremos, con la finalidad de generar un mejor ajuste, el modelo se ajustara con todas aquellas obervaciones que sean menores o iguales a 800,000 (por redondeo), estableciendo en este punto el filtro propuesto pora esta variable, que representaran un 86.2% de las obervaciones de esta variable y que adoptan la siguiente distribución.

```{r, echo=FALSE}
plot_1 = ggplot(filter(Train_copy_continuas, Current.Loan.Amount <= 80000000), aes(y=1, x=Current.Loan.Amount))+
  geom_jitter(aes(color=Loan.Status))+
  geom_violin(alpha=0.5) +
  geom_boxplot(width = 0.1, fill = "white", alpha = 0.5)+
  scale_y_continuous(NULL, labels = NULL)+
  scale_x_continuous(breaks = c(0, 200000, 400000, 600000, 800000),
                     labels = c("0", "200k", "400k", "600k", "800k"))+
  ggtitle("Variable Current.Loan.Amount posterior al filtro (valores < 800K)")+
  theme_bw()

plot_2 = ggplot(Train_copy_continuas, aes(y=1, x=Current.Loan.Amount))+
  geom_jitter(aes(color=Loan.Status))+
  geom_violin(alpha=0.5) +
  geom_boxplot(width = 0.1, fill = "white", alpha = 0.5)+
  scale_y_continuous(NULL, labels = NULL)+
  scale_x_continuous(breaks = c(0, 20000000, 40000000, 60000000, 80000000, 100000000),
                     labels = c("0", "20M", "40M", "60M", "80M", "100M"))+
  ggtitle("Variable Current.Loan.Amount previo al filtro")+
  theme_bw()

grid.arrange(plot_2, plot_1, ncol = 1)
```
La idea de este análisis particular es por un lado acotar la muestra eliminando valores extremos, y establecer un filtro de clásificación posterior a la predicción con el modelo ajustado.
Por lo que el resto de variables que superen este limite establecido a críterio para la variable `Current.Loan.Amount`, en el filtro manual por análisis exploratorio posterior a la predicción del modelo ajustado, serán calificadas automaticamente como `Fully Paid` (1).

- Análisis particular de la variable `Maximum.Open.Credit`

Dada la gráfica de comparación del grupo 2 (referenciar), se presume que si separamos los valores de `Maximum.Open.Credit` por Fully Paid (1) o Charged Off (0), encontraremos diferencias importantes en la distribución.

```{r}
plot_1 = ggplot(filter(Train_copy_continuas, Loan.Status == 1), aes(y=1, x=Maximum.Open.Credit))+
  geom_jitter(aes(color=Loan.Status))+
  geom_violin(alpha=0.5) +
  geom_boxplot(width = 0.1, fill = "white", alpha = 0.5)+
  scale_y_continuous(NULL, labels = NULL)+
  scale_x_continuous(breaks = c(0, 200000000, 400000000, 600000000, 800000000),
                     labels = c("0", "200M", "400M", "600M", "800M"))+
  scale_color_manual(values = c("deepskyblue"))+
  ggtitle("Variable Maximum.Open.Credit para clientes con Loan.Status = Fully Paid")+
  theme_bw()

plot_2 = ggplot(filter(Train_copy_continuas, Loan.Status == 0), aes(y=1, x=Maximum.Open.Credit))+
  geom_jitter(aes(color=Loan.Status))+
  geom_violin(alpha=0.5) +
  geom_boxplot(width = 0.1, fill = "white", alpha = 0.5)+
  scale_y_continuous(NULL, labels = NULL)+
  scale_x_continuous(breaks = c(0, 25000000, 50000000, 75000000, 100000000),
                     labels = c("0", "25M", "50M", "75M", "100M"))+
  ggtitle("Variable Maximum.Open.Credit para clientes con Loan.Status = Charged Off")+
  theme_bw()

plot_3 = ggplot(Train_copy_continuas, aes(y=1, x=Maximum.Open.Credit))+
  geom_jitter(aes(color=Loan.Status))+
  geom_violin(alpha=0.5) +
  geom_boxplot(width = 0.1, fill = "white", alpha = 0.5)+
  scale_y_continuous(NULL, labels = NULL)+
  scale_x_continuous(breaks = c(0, 200000000, 400000000, 600000000, 800000000),
                     labels = c("0", "200M", "400M", "600M", "800M"))+
  ggtitle("Variable Maximum.Open.Credit")+
  theme_bw()

grid.arrange(plot_3, plot_2, plot_1, ncol = 1)
```
Por un lado el valor máximo de la variable `Maximum.Open.Credit` cuando la variable `Loan.Status` es igual a Fully Paid (1) es de 798M, por el otro este mismo valor máximo pero para cuando la variable `Loan.Status` es igual a Charged Off (0) es de 98M. Con lo anterior podríamos establecer otro filtro manual por análisis exploratorio posterior a la predicción del modelo ajustado en donde todos los registros que adopen un valor superior a 100M `Maximum.Open.Credit` serán clásificados como `Fully Paid` (1).

Para esta variable se propone el filtro de valores presuntamente atípicos (Maximum.Open.Credit < 800K).

3er grupo:
- Análisis particular de la variable `Annual.Income`

Visualizando los cuantiles de `Annual.Income`.

```{r}
quantiles_("Annual.Income")
```

Destacar que el 75% de los valores del vector Annual.Income son menores o iguales a 1,726,247 El número de observaciones en el 4to cuartil es de 8551 con un valor máximo de 30,838,994, por lo que un filtro eliminando toda esta submuestra nos haría perder una buena parte de la muestra. Por lo que decidimos hacer un análisis más a fondo para encontrar el punto en donde solo filtremos los valores que sean más extremos.


Con el apoyo visual de la anterior gráfica podemos decidir filtrar todas aquellas observaciones de la variable Annual.Income que sean mayores a 4000000 De esta forma, para el filtro de las sumuestras eliminariamos 572 variables de la muestra, representando un 1.67% de la misma.

```{r, echo=FALSE}
nrow(filter(Train_copy_continuas, Annual.Income > 4000000))
```
```{r, echo=FALSE}
plot_1 = ggplot(filter(Train_copy_continuas, Annual.Income <= 4000000), aes(y=1, x=Annual.Income))+
  geom_jitter(aes(color=Loan.Status))+
  geom_violin(alpha=0.5) +
  geom_boxplot(width = 0.1, fill = "white", alpha = 0.5)+
  scale_y_continuous(NULL, labels = NULL)+
  scale_x_continuous(breaks = c(0, 1000000, 2000000, 3000000, 4000000, 5000000),
                     labels = c("0", "1M", "2M", "3M", "4M", "5M"))+
  ggtitle("Variable Annual.Income posterior al filtro (valores < 4M)")+
  theme_bw()

plot_2 = ggplot(Train_copy_continuas, aes(y=1, x=Annual.Income))+
  geom_jitter(aes(color=Loan.Status))+
  geom_violin(alpha=0.5) +
  geom_boxplot(width = 0.1, fill = "white", alpha = 0.5)+
  scale_y_continuous(NULL, labels = NULL)+
  scale_x_continuous(breaks = c(0, 5000000, 10000000, 20000000, 30000000),
                     labels = c("0", "5M", "10M", "20M", "30M"))+
  ggtitle("Variable Annual.Income previo al filtro")+
  theme_bw()

grid.arrange(plot_2, plot_1, ncol = 1)
```
Para esta variable no se encuentran patrones de cumplimiento y se propone el filtro de valores presuntamente atípicos (Annual.Income < 4M).

4to grupo:
- Análisis particular de la variable `Current.Credit.Balance`

```{r}
quantiles_("Current.Credit.Balance")
```


En este punto cabe destacar que el 75% de los valores del vector Current.Credit.Balance son menores o iguales a 327,180.4 El número de observaciones en el 4to cuartil es de 8,552, por lo que un filtro eliminando toda esta submuestra nos haría perder una buena parte de la muestra. Por lo que decidimos hacer un análisis más a fondo para encontrar el punto en donde solo filtremos los valores que sean más extremos.

Con el apoyo visual de la siguiente gráfica pudimos decidir filtrar todas aquellas observaciones de la variable Current.Credit.Balance que sean mayores a 1000000 De esta forma, eliminariamos 588 variables de la muestra, representando un 1.71% de la misma.

```{r, echo=FALSE, include=FALSE}
nrow(filter(Train_copy_continuas, Current.Credit.Balance > 1000000))
```

```{r, echo=FALSE}
plot_1 = ggplot(filter(Train_copy_continuas, Current.Credit.Balance <= 1000000), aes(y=1, x=Current.Credit.Balance))+
  geom_jitter(aes(color=Loan.Status))+
  geom_violin(alpha=0.5) +
  geom_boxplot(width = 0.1, fill = "white", alpha = 0.5)+
  scale_y_continuous(NULL, labels = NULL)+
  scale_x_continuous(breaks = c(0, 250000, 500000, 750000),
                     labels = c("0", "250K", "500K", "750K"))+
  ggtitle("Variable Current.Credit.Balance posterior al filtro (valores < 1M)")+
  theme_bw()

plot_2 = ggplot(Train_copy_continuas, aes(y=1, x=Current.Credit.Balance))+
  geom_jitter(aes(color=Loan.Status))+
  geom_violin(alpha=0.5) +
  geom_boxplot(width = 0.1, fill = "white", alpha = 0.5)+
  scale_y_continuous(NULL, labels = NULL)+
  scale_x_continuous(breaks = c(0, 2000000, 4000000, 6000000),
                     labels = c("0", "2M", "4M", "6M"))+
  ggtitle("Variable Current.Credit.Balance previo al filtro")+
  theme_bw()

grid.arrange(plot_2, plot_1, ncol = 1)
```
Para esta variable no se encuentran patrones de cumplimiento y se propone el filtro de valores presuntamente atípicos (Current.Credit.Balance < 1M).


- Análisis particular de la variable `Monthly.Debt`

Visualizando los quantiles de `Monthly.Debt`

```{r}
quantiles_("Monthly.Debt")
```

En este punto cabe destacar que el 75% de los valores del vector Monthly.Debt son menores o iguales a 24,554.97 El número de observaciones en el 4to cuartil es de 8,553, por lo que un filtro eliminando toda esta submuestra nos haría perder una buena parte de la muestra. Por lo que decidimos hacer un análisis más a fondo para encontrar el punto en donde solo filtremos los valores que sean más extremos.

Con el apoyo visual de la siguiente gráfica pudimos decidir filtrar todas aquellas observaciones de la variable Current.Credit.Balance que sean mayores a 50,000 De esta forma, eliminariamos 781 variables de la muestra, representando un 2.28% de la misma.

```{r, echo=FALSE, include=FALSE}
nrow(filter(Train_copy_continuas, Monthly.Debt > 50000))
```

```{r}
plot_1 = ggplot(filter(Train_copy_continuas, Monthly.Debt <= 50000), aes(y=1, x=Monthly.Debt))+
  geom_jitter(aes(color=Loan.Status))+
  geom_violin(alpha=0.5) +
  geom_boxplot(width = 0.1, fill = "white", alpha = 0.5)+
  scale_y_continuous(NULL, labels = NULL)+
  scale_x_continuous(breaks = c(0, 10000, 20000, 30000, 40000, 50000),
                     labels = c("0", "10K", "20K", "30K", "40K", "50K"))+
  ggtitle("Variable Monthly.Debt posterior al filtro (valores < 50000)")+
  theme_bw()

plot_2 = ggplot(Train_copy_continuas, aes(y=1, x=Monthly.Debt))+
  geom_jitter(aes(color=Loan.Status))+
  geom_violin(alpha=0.5) +
  geom_boxplot(width = 0.1, fill = "white", alpha = 0.5)+
  scale_y_continuous(NULL, labels = NULL)+
  scale_x_continuous(breaks = c(0, 25000, 50000, 100000, 150000, 200000),
                     labels = c("0", "25K", "50K", "100K", "150K", "200K"))+
  ggtitle("Variable Annual.Income previo al filtro")+
  theme_bw()

grid.arrange(plot_2, plot_1, ncol = 1)
```
Para esta variable se encuentran patrones de cumplimiento en aquellos clientes con valores en `Monthly.Debt` mayores a 125K, por lo que esta observación pasa a formar parte del filtro manual por análisis exploratorio posterior a la predicción del modelo ajustado en donde todos los registros que adopen un valor superior a 125K `Monthly.Debt` serán clásificados como `Fully Paid` (1). Además, se propone el filtro de valores presuntamente atípicos (Current.Credit.Balance < 1M).

6to grupo:
- Análisis particular de la variable `Credit.Score`

La situación de la distribución de los valores parece ser un poco similar al caso de la variable `Current.Loan.Amount`, por lo que se buscara proponer filtrar los registros de aquellas observaciones extremas para la variable Credit.Score en estudio. Cuando la media el score crediticio se encuentra en 1048.483, los valores de esta variable mayores a 5mil empiezan a perder mucho sentido, generandonos dudas sobre si estos datos se recopilaron apropiadamente o son inexactos como para ponerles un tope.

Por un lado se análizan los cuartiles del vector y se elaboran dos gráficas de cajas y bigotes más una capa de violin, además de un histógrama: una para valores que se encuentre en el primer, segundo y tercer cuartil y otra para el cuarto cuartil.

```{r}
quantiles_("Credit.Score")
```

```{r}
train_selected = Train_copy_continuas %>% filter(Credit.Score <= 738) %>% select(Credit.Score, Loan.Status)
train_long_form8 = gather(train_selected, key = "variable", value = "valor", -Loan.Status)

plot_1 = ggplot(train_long_form8, aes(y=variable, x=valor))+
  geom_jitter(aes(color=Loan.Status))+
  geom_violin(alpha=0.5) +
  geom_boxplot(width = 0.1, fill = "white", alpha = 0.5)+
  # geom_jitter()+ 
  stat_summary(fun=mean, colour="darkred", geom="point",
               shape=18, size=3, show.legend=FALSE)+
  scale_y_discrete(NULL)+
  ggtitle(glue("Credit.Score posterior al filtro (valores menores o iguales a 753)"))+
  theme_bw()

train_selected = Train_copy_continuas %>% select(Credit.Score, Loan.Status)
train_long_form9 = gather(train_selected, key = "variable", value = "valor", -Loan.Status)

plot_2 = ggplot(train_long_form9, aes(y=variable, x=valor))+
  geom_jitter(aes(color=Loan.Status))+
  geom_violin(alpha=0.5) +
  geom_boxplot(width = 0.1, fill = "white", alpha = 0.5)+
  # geom_jitter()+ 
  stat_summary(fun=mean, colour="darkred", geom="point",
               shape=18, size=3, show.legend=FALSE)+
  scale_y_discrete(NULL)+
  ggtitle(glue("Credit.Score previo al filtro"))+
  theme_bw()

grid.arrange(plot_2, plot_1, ncol = 1)
```
```{r}
train_selected = Train_copy_continuas %>% select(Credit.Score, Loan.Status)
train_long_form9 = gather(train_selected, key = "variable", value = "valor", -Loan.Status)

plot_1 = ggplot(filter(train_long_form9, Loan.Status == 1), aes(y=variable, x=valor))+
  geom_jitter(aes(color=Loan.Status))+
  geom_violin(alpha=0.5) +
  geom_boxplot(width = 0.1, fill = "white", alpha = 0.5)+
  # geom_jitter()+ 
  stat_summary(fun=mean, colour="darkred", geom="point",
               shape=18, size=3, show.legend=FALSE)+
  scale_y_discrete(NULL)+
  scale_color_manual(values = c("deepskyblue"))+
  ggtitle(glue("Credit.Score para clientes con Loan.Status = 1"))+
  theme_bw()


plot_2 = ggplot(filter(train_long_form9, Loan.Status == 0), aes(y=variable, x=valor))+
  geom_jitter(aes(color=Loan.Status))+
  geom_violin(alpha=0.5) +
  geom_boxplot(width = 0.1, fill = "white", alpha = 0.5)+
  # geom_jitter()+ 
  stat_summary(fun=mean, colour="darkred", geom="point",
               shape=18, size=3, show.legend=FALSE)+
  scale_y_discrete(NULL)+
  ggtitle(glue("Credit.Score para clientes con Loan.Status = 0"))+
  theme_bw()

grid.arrange(plot_2, plot_1, ncol = 1)
```


Para esta variable si se encuentran patrones claros de incumplimiento en aquellos clientes con valores en `Credit.Score` mayores a 6K, por lo que esta observación pasa a formar parte del filtro manual por análisis exploratorio posterior a la predicción del modelo ajustado en donde todos los registros que adopen un valor superior a 6K `Credit.Score` serán clásificados como `Charged off` (0). Además, se propone el filtro de valores presuntamente atípicos (Current.Credit.Balance < 753).

7mo grupo:
`Tax.Liens` y `Bankruptcies`

Se decide no emplear filtros para este grupo.

A resaltar del análisis univariado y bivariado:

EN EL PERIODO DEL CREDITO
- Son más los clientes que solicitan un crédito a corto plazo (70%) que los que solicitan a LP (30%)
- Aquellos clientes con default son el grupo predominante en el gpo de clientes que solicitaron un  crédito a largo plazo
- La mediana del current loan es más alta para clientes con creditos CP que a LP, corroborar la media porque se notan outliers altos en CP.
- Son más los clientes con una hipóteca que piden crédito a LP que a CP, que los clientes que rentan su vivienda con créditos a CP que a LP. (variacion > 10%)
- La media de la deuda actual del cliente es mayor para los clientes que solicitan un crédito a LP, que uno a CP, lo cual tiene logica de negocio.
- La media del credit score es mayor para los clientes que solicitan crédito a CP que a LP.


EN LOS AÑOS DE TRABAJO DEL CLIENTE:
- El grupo que predomina es el de > 10 años de trabajo con un 35%, seguido de 2 años con un 8.5% 


EN EL DUEÑO DE LA VIVIENDA:
- Destaca el grupo de clientes con hipóteca con un 51%, seguido de Renta con un 39% y solo casa propia con un 9%
- Hay dos factores que se podrían unificar: have mortgage & home mortgage, aunque la prop del primeor es de 0.2% por lo que no vale la pena

EN EL PROPOSITO DEL CRÉDITO:
- Destaca con un 73% el proposito de consolidación de la deuda como proposito declarado. 

EN LAS BANCARROTAS:
- El 65% de los clientes declara nunca haber caído en bancarrota, le sigue el 25% con al menos una bancarrota.
- El grupo, por proposito del crédito, que predomina en una bancarrota declarada es aquel grupo que declara solicitar el crédito para "moving"
- La mediana del numero máximo de creditos abiertos se relaciona negativamente con el número de bancarrotas. Entre más bancarrotas es menor el numero de créditos abiertos.

EN LA DEUDA ACTUAL DEL CLIENTE:
- La mediana de la deuda tiene una relación negativa con el aumento en el credit scoring, a mayor credit score menor es la mediana (falta corroborar la media dado outliers en altos credit scores)
- la mediana sigue una relacion positiva con el ingreso anual (corroborar media)
- la mediana sigue una relacion positiva con la deuda mensual (corroborar media)
- la mediana sigue una relacion positiva con el balance crediticio (corroborar media)

EN LOS AÑOS DE HISTORIAL CREDITICIO:

- La mediana de los años mantiene una relacion positiva con el balance crediticio

EN EL BALANCE ACTUAL DEL CREDITO:
- La mediana del balance mantiene una relacion positiva con el maximo de creditos abiertos.

EN EL CREDIT SCORING:
- Todos aquellos clientes que presentan un credit score > 5,800, también presentan el valor de `Charged off` en la variable de respuesta binaria `Loan.Status`.


- Configuración del filtro manual por análisis exploratorio posterior a la predicción del modelo ajustado:

La variable Loan.Status adoptara el valor de 1 (`Fully Paid`) cuando:
- El registro presente más de 50 unidades en la variable `Number.of.Open.Accounts`.
- El registro presente un valor mayor a 50M en la variable `Current.Loan.Amount`
- El registro presente un valor mayor a 100M en la variable `Maximum.Open.Credit`
- El registro presente un valor mayor a 125K en la variable `Monthly.Debt`

La variable Loan.Status adoptara el valor de 0 (`Charged off`) cuando:
- El registro presente un valor mayor a 6K en la variable `Credit.Score`



En este apartado generamos los nuevos datasets a estudiar en siguientes scripts


- Modelado con toda la muestra.
- Modelado con una submuestra (filtro en 11 variables continuas)


Muestra completa
```{r}
write_csv(Train_copy, "../datasets/muestra_completa.csv")
```

```{r}
Train_copy_1_continues = Train_copy %>% select(Current.Loan.Amount, Credit.Score, Annual.Income, Monthly.Debt, Years.of.Credit.History, Months.since.last.delinquent, Number.of.Open.Accounts, Current.Credit.Balance, Maximum.Open.Credit, Bankruptcies, Tax.Liens)

chart.Correlation(select(Train_copy_1_continues, -c(Tax.Liens)), histogram=TRUE, pch=19, main = "Matriz de correlaciones con histógrama muestra completa")
```


Muestra reducida no. 1, en donde se propondrá un modelo con el 32% de la muestra original.
```{r}
Train_copy_2 = Train_copy %>% filter(Current.Loan.Amount <= 80000000, Credit.Score <= 753, Maximum.Open.Credit <= 80000000, Years.of.Credit.History <= 40, Number.of.Open.Accounts <= 30, Months.since.last.delinquent <= 30, Current.Loan.Amount <= 80000000, Annual.Income <= 4000000, Current.Credit.Balance <= 1000000, Monthly.Debt <= 50000, Credit.Score <= 753)

print(glue("Train_copy en un inicio tuvó {format(nrow(Train_copy), big.mark = ',')} obs"))
print(glue("Train_copy_2 ahora tiene {format(nrow(Train_copy_2), big.mark = ',')} obs"))
print(glue("Se redujo el dataset en un {(1 - (nrow(Train_copy_2)/nrow(Train_copy)))*100 }%"))

write_csv(Train_copy_2, "../datasets/muestra_reducida_2.csv")
```

```{r}
Train_copy_1_continues = Train_copy_2 %>% select(Current.Loan.Amount, Credit.Score, Annual.Income, Monthly.Debt, Years.of.Credit.History, Months.since.last.delinquent, Number.of.Open.Accounts, Current.Credit.Balance, Maximum.Open.Credit, Bankruptcies, Tax.Liens)

chart.Correlation(select(Train_copy_1_continues, -c(Tax.Liens)), histogram=TRUE, pch=19, main = "Matriz de correlaciones con histógrama muestra reducida no. 2")
```


La continuación de este proyecto, que es la parte del modelado, continuará en los rmarkdown modelo 1 y modelo 2. En cada uno de estos rmarkdowns donde se plantea ajustar el mejor modelo dada la submuestra analizada, separando Train y Test, empleando selección de variables, validación cruzada y bootstrap, finalizando con generar un archivo RData de cada modelo así como un diagnostico con el estadístico PRESS.

La idea principal de esto es llevar cada modelo a una validación cruzada simulada con la muestra Test que será evaluada en el proyecto final de clase.



















