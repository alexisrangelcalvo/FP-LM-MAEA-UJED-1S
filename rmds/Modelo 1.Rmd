---
title: "Modelo 1"
author: "Alexis Rangel"
date: "2023-04-16"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, carga de librerias, echo=FALSE}
library(tidyverse)
library(gridExtra)
library(glue)
library(caret)
library(ROCR)
library(olsrr)
library(leaps)
library(boot)
library(Amelia)
library(car)
library(RColorBrewer)
library(paletteer)
library(MASS)
library(glmulti) # Automated model selection and model-averaging. (see more here https://rstudio-pubs-static.s3.amazonaws.com/2897_9220b21cfc0c43a396ff9abf122bb351.html)
library(boot)
library(vcd)
library(ggside)
```

```{r, carga de datos, echo=FALSE}
Train_1 = read.csv("../datasets/muestra_completa.csv")

set.seed(123) # Establecer la semilla para obtener siempre la misma muestra aleatoria
Train_intern_1 <- sample_frac(Train_1, 0.75)
Test_intern_1 <- setdiff(Train_1, Train_intern_1)

# nrow(Train_1)
# nrow(Train_intern_1) + nrow(Test_intern_1) 
```

```{r, carga de datos, echo=FALSE}
Train_intern_1 = dplyr::select(Train_intern_1, -c(ID))
Test_intern_1 = dplyr::select(Test_intern_1, -c(ID))
#Train_copy_1$Loan.Status = as.factor(Train_copy_1$Loan.Status) 
```



### Modelo de regresión logística.

##### Alcance y objetivo del modelo.

El presente ejercicio se plantea ajustar un modelo que tenga el mejor performance con la muestra completa, con la finalidad de ser evaluado ante la muestra de Test.

##### Ajuste del modelo


- Visualizaciones del modelo de regresion linea simple

```{r, echo=FALSE}
plot_lrm_1 = ggplot(Train_intern_1, aes(x=Credit.Score, y=Loan.Status)) +
  geom_jitter(height = .02, width = 0, alpha = 0.3) + 
  stat_smooth(method="glm", 
              method.args=list(family="binomial"), se=FALSE)+
  ggtitle("Logit ~Credit.Score")+
  theme_bw()

plot_lrm_2 = ggplot(Train_intern_1, aes(x=Current.Loan.Amount, y=Loan.Status)) +
  geom_jitter(height = .02, width = 0, alpha = 0.3) + 
  stat_smooth(method="glm", 
              method.args=list(family="binomial"), se=FALSE)+
  ggtitle("Logit ~Current.Loan.Amount")+
  theme_bw()

plot_lrm_3 = ggplot(Train_intern_1, aes(x=Annual.Income, y=Loan.Status)) +
  geom_jitter(height = .02, width = 0, alpha = 0.3) + 
  stat_smooth(method="glm", 
              method.args=list(family="binomial"), se=FALSE)+
  ggtitle("Logit ~Annual.Income")+
  theme_bw()

plot_lrm_4 = ggplot(Train_intern_1, aes(x=Monthly.Debt, y=Loan.Status)) +
  geom_jitter(height = .02, width = 0, alpha = 0.3) + 
  stat_smooth(method="glm", 
              method.args=list(family="binomial"), se=FALSE)+
  ggtitle("Logit ~Monthly.Debt")+
  theme_bw()

plot_lrm_5 = ggplot(Train_intern_1, aes(x=Years.of.Credit.History, y=Loan.Status)) +
  geom_jitter(height = .02, width = 0, alpha = 0.3) + 
  stat_smooth(method="glm", 
              method.args=list(family="binomial"), se=FALSE)+
  ggtitle("Logit ~Years.of.Credit.History")+
  theme_bw()

plot_lrm_6 = ggplot(Train_intern_1, aes(x=Months.since.last.delinquent, y=Loan.Status)) +
  geom_jitter(height = .02, width = 0, alpha = 0.3) + 
  stat_smooth(method="glm", 
              method.args=list(family="binomial"), se=FALSE)+
  ggtitle("Logit ~Months.since.last.delinquent")+
  theme_bw()

plot_lrm_7 = ggplot(Train_intern_1, aes(x=Number.of.Open.Accounts, y=Loan.Status)) +
  geom_jitter(height = .02, width = 0, alpha = 0.3) + 
  stat_smooth(method="glm", 
              method.args=list(family="binomial"), se=FALSE)+
  ggtitle("Logit ~Number.of.Open.Accounts")+
  theme_bw()

plot_lrm_8 = ggplot(Train_intern_1, aes(x=Current.Credit.Balance, y=Loan.Status)) +
  geom_jitter(height = .02, width = 0, alpha = 0.3) + 
  stat_smooth(method="glm", 
              method.args=list(family="binomial"), se=FALSE)+
  ggtitle("Logit ~Current.Credit.Balance")+
  theme_bw()

plot_lrm_9 = ggplot(Train_intern_1, aes(x=Maximum.Open.Credit, y=Loan.Status)) +
  geom_jitter(height = .02, width = 0, alpha = 0.3) + 
  stat_smooth(method="glm", 
              method.args=list(family="binomial"), se=FALSE)+
  ggtitle("Logit ~Maximum.Open.Credit")+
  theme_bw()

plot_lrm_10 = ggplot(Train_intern_1, aes(x=Bankruptcies, y=Loan.Status)) +
  geom_jitter(height = .02, width = 0, alpha = 0.3) + 
  stat_smooth(method="glm", 
              method.args=list(family="binomial"), se=FALSE)+
  ggtitle("Logit ~Bankruptcies")+
  theme_bw()

plot_lrm_11 = ggplot(Train_intern_1, aes(x=Tax.Liens, y=Loan.Status)) +
  geom_jitter(height = .02, width = 0, alpha = 0.3) + 
  stat_smooth(method="glm", 
              method.args=list(family="binomial"), se=FALSE)+
  ggtitle("Logit ~Tax.Liens")+
  theme_bw()

grid.arrange(plot_lrm_1, plot_lrm_2, plot_lrm_3, plot_lrm_4, plot_lrm_5, plot_lrm_6, plot_lrm_7, plot_lrm_8, plot_lrm_9, plot_lrm_10, plot_lrm_11, ncol = 4)

```

Gráfica no. 1 (Logit simple glm(Loan.Status ~. ))

```{r, echo=FALSE}
rm(plot_lrm_1, plot_lrm_2, plot_lrm_3, plot_lrm_4, plot_lrm_5, plot_lrm_6, plot_lrm_7, plot_lrm_8, plot_lrm_9, plot_lrm_10, plot_lrm_11)
```


¿Qué se puede concluir del anterior GRID?


######  Ajuste del modelo no. 1
```{r}
modelo_1 = glm(data = Train_intern_1, 
              formula = Loan.Status~., family = "binomial")
summary(modelo_1)
```
Salida de consola y código no.1 (Ajuste del modelo no.1 )

######  Update del modelo con las variables estadísticamente significativas
```{r}
modelo_1 = update(object = modelo_1, formula. = .~.-Home.Ownership -Number.of.Open.Accounts -Number.of.Credit.Problems -Current.Credit.Balance -Bankruptcies -Tax.Liens -Months.since.last.delinquent -Maximum.Open.Credit)
summary(modelo_1)
```
Salida de consola y código no.2 (Update al modelo no.1)

El modelo 1 tiene un AIC de 19828, la version que contempla todos los predictores era de 19797
######  Anova del modelo
```{r}
anova(modelo_1)
```
Salida de consola y código no.3 (ANOVA Modelo no. 1)

##### Selección de variables en modelo de regresion logistica por críterio de información AIC

```{r}
glmulti.logistic.out <-
    glmulti(Loan.Status ~.-Home.Ownership -Number.of.Open.Accounts -Number.of.Credit.Problems -Current.Credit.Balance -Bankruptcies -Tax.Liens -Months.since.last.delinquent -Maximum.Open.Credit, data = Train_intern_1,
            level = 1,               # No interaction considered
            method = "h",            # Exhaustive approach
            crit = "aic",            # AIC as criteria
            confsetsize = 5,         # Keep 5 best models
            plotty = F, report = F,  # No plot or interim reports
            fitfunction = "glm",     # glm function
            family = binomial)       # binomial family for logistic regression

## Show 5 best models (Use @ instead of $ for an S4 object)
glmulti.logistic.out@formulas
```
Salida de consola y código no.4 (Selección de variables)-

```{r, include=FALSE}
### CON INTERACCIONES TARDA MUCHISIMO (MÁS DE 1 hora y media Y SIN TERMINAR)
# glmulti.logistic.out <- glmulti(Loan.Status ~.-Home.Ownership -Number.of.Open.Accounts -Number.of.Credit.Problems -Current.Credit.Balance -Bankruptcies -Tax.Liens -Months.since.last.delinquent -Maximum.Open.Credit, data = Train_intern_1,
#                                 level = 2,                   # Considerar interacciones de segundo orden
#                                 method = "h",                # Enfoque exhaustivo
#                                 crit = "aic", # Considerar AIC, BIC y R-squared ajustado
#                                 confsetsize = 5,             # Mantener 5 mejores modelos
#                                 plotty = FALSE,               # Mostrar gráfico
#                                 report = FALSE,              # No informes intermedios
#                                 fitfunction = "glm",         # Función de ajuste glm
#                                 family = binomial)   
```

De entrada, el mejor modelo por AIC que propone la funcion glmulti() es el mismo modelo de regresión logística que se le pasó por parametro, por lo que podemos hablar de que ese al momento es el modelo ideal, con 8 features. Sin embargo en segundo y tercer lugar proponé modelos con 7 features, por lo que se evaluará contra validación cruzada la viabilidad de irnos por un modelo más ligero. 


- Modelo 1.2
```{r}
#Modelo 1.2
modelo_1_2 = glm(data = Train_intern_1, 
              formula = Loan.Status~ Term + Purpose + Current.Loan.Amount + Credit.Score + Annual.Income + Monthly.Debt + Years.of.Credit.History, family = "binomial")
summary(modelo_1_2)
```
El modelo 1.2 tiene un AIC de 19832

Salida de consola y código no.5 (Ajustando modelo no. 1.2)-

```{r}
anova(modelo_1_2)
```
Salida de consola y código no.6 (ANOVA modelo no. 1.2)-

- Modelo 1.3

```{r}
#Modelo 1.3
modelo_1_3 = glm(data = Train_intern_1, 
              formula = Loan.Status~ Term + Years.in.current.job + Purpose + Current.Loan.Amount + Credit.Score + Annual.Income + Monthly.Debt, family = "binomial")
summary(modelo_1_3)
```
El modelo 1.2 tiene un AIC de 19843

Salida de consola y código no.7 (Ajustando modelo no. 1.3)-


##### Validación cruzada y MSPR

Del modelo base y los dos modelos que derivan de este, que además presentan la ventaja de contar con una feature menos, se evaluara cada uno por validación cruzada y por MSPR para solo quedarnos con el mejor.

- Validación por k-fold para el modelo base
```{r}
suppressWarnings(MSE_kf_1 <- cv.glm(data = Test_intern_1,
               glmfit = modelo_1, 
               K = 50))
MSE_kf_1$delta
```
Salida de consola y código no.8 (MSPR por K-Pliegues del modelo no. 1)-

Interpretando  `$delta`:

El primer valor representa el error medio cuadrático promedio para los K pliegues (MSPR o Mean Squared Prediction Error), y el segundo valor representa la desviación estándar de los errores medios cuadráticos de los K pliegues.

- Validación por k-fold para el modelo 1.2
```{r}
suppressWarnings(MSE_kf_1_2 <- cv.glm(data = Test_intern_1,
               glmfit = modelo_1_2, 
               K = 50))
MSE_kf_1_2$delta
```
Salida de consola y código no.9 (MSPR por K-Pliegues del modelo no. 1.2)-

- Validación por k-fold para el modelo 1.3
```{r}
suppressWarnings(MSE_kf_1_3 <- cv.glm(data = Test_intern_1,
               glmfit = modelo_1_3, 
               K = 50))
MSE_kf_1_3$delta
```
Salida de consola y código no. 10 (MSPR por K-Pliegues del modelo no. 1.3)-

Concluimos que los dos modelos que derivan del modelo base (donde la diferencia solo se da en que el primero incluye Years.of.Credit.History y el segundo Years.in.current.job) con solo 7 features presentan ligeramente un MSPR menor, contra el conjunto de Test, que el modelo base además de incluir una variable menos, por lo que dichos modelos pasan a la etapa de remuestreo y el estudio de la matriz de confusión con la finalidad de proponer el de mejor performance en estas 2 instancias.


##### Modelo no 1.2

- Respuesta del modelo en el conjunto de prueba

```{r, echo=FALSE}
prediccion_2 = predict(object = modelo_1_2,
                    newdata = Test_intern_1, type = "response")
boxplot(prediccion_2)
```
Gráfica no. 2 (Distribución de la predicción para el modelo no 1.2)-

- punto de corte ideal para maximizar la sensibilidad (vs Test)

```{r}
prediccion_2 = predict(object = modelo_1_2,
                    newdata = Test_intern_1, type = "response")

Exactitud_1 <- vector()
Corte_1 <- seq(0.05, 0.95, by = 0.001)

for (i in 1:length(Corte_1)) {
  Prediccion <- as.factor(ifelse(prediccion_2 >= Corte_1[i], yes = 1, no = 0))
  
  Exactitud_1[i] <- tryCatch(
    {
      # confusionMatrix(data = as.factor(Test_intern_1$Loan.Status), Prediccion)$overall[1]
      confusionMatrix(data = as.factor(Test_intern_1$Loan.Status), 
                             Prediccion)$byClass[1]
    },
    error = function(e) {
      0 # O cualquier valor predeterminado
    }
  )
}

plot(x=Corte_1, y = Exactitud_1, type = "l", main ="Punto de corte óptimo para maximizar la sensibilidad (vs Test)", xlab="Corte", ylab="Exactitud")
```
Gráfica no. 3 (punto de corte ideal para maximizar la sensibilidad (vs Test))-

- punto de corte ideal para maximizar la sensibilidad (vs Test)

```{r}
prediccion_2 = predict(object = modelo_1_2,
                    newdata = Test_intern_1, type = "response")

Exactitud_1 <- vector()
Corte_1 <- seq(0.05, 0.95, by = 0.001)

for (i in 1:length(Corte_1)) {
  Prediccion <- as.factor(ifelse(prediccion_2 >= Corte_1[i], yes = 1, no = 0))
  
  Exactitud_1[i] <- tryCatch(
    {
      # confusionMatrix(data = as.factor(Test_intern_1$Loan.Status), Prediccion)$overall[1]
      confusionMatrix(data = as.factor(Test_intern_1$Loan.Status), 
                             Prediccion)$byClass[2]
    },
    error = function(e) {
      0 # O cualquier valor predeterminado
    }
  )
}

plot(x=Corte_1, y = Exactitud_1, type = "l", main ="Punto de corte óptimo para maximizar la especificidad (vs Test)", xlab="Corte", ylab="Exactitud")
```

Gráfica no. 4 (punto de corte ideal para maximizar la especificidad (vs Test))-


- punto de corte ideal para maximizar la exactitud (vs Test)

```{r}

prediccion_2 = predict(object = modelo_1_2,
                    newdata = Test_intern_1, type = "response")

Exactitud_1 <- vector()
Corte_1 <- seq(0.05, 0.95, by = 0.001)

for (i in 1:length(Corte_1)) {
  Prediccion <- as.factor(ifelse(prediccion_2 >= Corte_1[i], yes = 1, no = 0))
  
  Exactitud_1[i] <- tryCatch(
    {
      confusionMatrix(data = as.factor(Test_intern_1$Loan.Status), Prediccion)$overall[1]
    },
    error = function(e) {
      0 # O cualquier valor predeterminado
    }
  )
}

plot(x=Corte_1, y = Exactitud_1, type = "l", main ="Punto de corte óptimo para maximizar la exactitud (vs Test)", xlab="Corte", ylab="Exactitud")
```
Gráfica no. 5 (punto de corte ideal para maximizar la exactitud (vs Test))-

```{r}
corte_optimo_1 = which(Exactitud_1==max(Exactitud_1))
Corte_1[corte_optimo_1][1]
```
Salida de consola y código no. 11 (Corte ótimo para máximizar la exactitud)-


###### Matriz de confusión para el modelo 1.2

<!-- ```{r, include=FALSE} -->
<!-- Prediccion_2<-as.factor(ifelse(prediccion_2>=Corte_1[corte_optimo_1][1],yes = 1, no = 0)) -->

<!-- filtro_criterio_EDA = ifelse(Test_intern_1$Number.of.Open.Accounts > 50 | Test_intern_1$Current.Loan.Amount > 50000000 | Test_intern_1$Maximum.Open.Credit > 100000000 | Test_intern_1$Monthly.Debt > 125000, TRUE, FALSE) -->

<!-- filtro_criterio_EDA_2 = ifelse(Test_intern_1$Credit.Score > 6000, FALSE, TRUE) -->

<!-- #Prediccion_2_modified = ifelse(filtro_criterio_EDA, Prediccion_2, Prediccion_2) -->

<!-- Prediccion_2_modified[!filtro_criterio_EDA] <- 2 -->

<!-- table(Prediccion_2_modified) -->

<!-- ``` -->


```{r}
Prediccion_2<-as.factor(ifelse(prediccion_2>=Corte_1[corte_optimo_1][1],yes = 1, no = 0))

confusionMatrix(data = as.factor(Test_intern_1$Loan.Status), 
                             Prediccion_2)

cfmx2 = confusionMatrix(data = as.factor(Test_intern_1$Loan.Status), 
                             Prediccion_2)
```
Salida de consola y código no. 12 (Matriz de confusión para el modelo no 1.2)-

```{r}
mosaic(cfmx2$table, shade = T, colorize = T,
       gp = gpar(fill = matrix(c("green3", "red2", "red2", "green3"), 2, 2)),
       main = "Matriz de confusión")
```
Salida de consola y código no. 13 (Matriz de confusión ilustrada para el modelo no 1.2)-

###### Curva ROC

```{r}
##### Comparar modelo ya ajustado (no.1) con uno nuevo y muy simple
Prediccion_2_roc<-predict(object = modelo_1_2,
                    newdata = Test_intern_1, type = "response", 
                    se.fit = T)

predicciones_roc_2=prediction(Prediccion_2_roc$fit,Test_intern_1$Loan.Status)
Desempeno_roc_2<-performance(predicciones_roc_2,'tpr','fpr')

## Cgenerando nuevo modelo simple
modelo_simple_prueba <- glm(data = Train_intern_1, 
              formula = Loan.Status~Purpose+Bankruptcies, family = "binomial")

Prediccion_1_prueba<-predict(object = modelo_simple_prueba,
                    newdata = Test_intern_1, type = "response", 
                    se.fit = T)

predicciones1_prueba<-prediction(Prediccion_1_prueba$fit,Test_intern_1$Loan.Status)
Desempeno1_prueba<-performance(predicciones1_prueba,'tpr','fpr')

#ejecutar en conjunto
plot(Desempeno_roc_2,col="darkgreen")
plot(Desempeno1_prueba, col = "firebrick", add = T)
```
Gráfica no. 6 (Curva ROC modelo 1.2)-

######  Identificando los coeficientes modelo no.2

```{r, echo=FALSE}
nombres_vars = names(coef(modelo_1_2))
resumen = summary(modelo_1_2)

# Iterar por cada variable e imprimir su nombre y coeficiente
for (i in seq_along(nombres_vars)) {
  cat(paste(nombres_vars[i], ": ", resumen$coefficients[i, "Estimate"], "\n"))
}
```
Salida de consola y código no. 14 (Coeficientes modelo no 1.2)-

###### Intervalos de confianza modelo no.2

```{r, echo=FALSE}
confint(object = modelo_1_2, level = 0.95)
```
Salida de consola y código no. 15 (Intervalos de confianza para el modelo no 1.2)-

######  ODDS Ratios del modelo no 1.2
- Identificando los odds ratios 
$e^{B_{k}}$

```{r, echo=FALSE}
nombres_vars = names(coef(modelo_1_2))
resumen = summary(modelo_1_2)

# Iterar por cada variable e imprimir su nombre y el num de euler elevado al coeficiente
for (i in seq_along(nombres_vars)) {
  cat(paste(nombres_vars[i], ": ", exp(resumen$coefficients[i, "Estimate"]), "\n"))
}
```
Salida de consola y código no. 16 (Odds ratios para el modelo no 1.2)-

######  Interpretación Odds ratios en el modelo 1.2

- Si la variable `Term` adopta el valor `Short`, este evento estara asociado con un aumento del 68% en las probabilidades del pago al corriente (`Fully Paid`) comparado con el evento cuando `Term` adopa el valor de `Long`.
- Si la variable `Purpose` adopta el `buy a car`, este evento estara asociado con un aumento del 266% en las probabilidades del pago al corriente (`Fully Paid`)
- Si la variable `Purpose` adopta el `buy a house`, este evento estara asociado con un aumento del 44% en las probabilidades del pago al corriente (`Fully Paid`)
- Si la variable `Purpose` adopta el valor `debt consolidation`, este evento estara asociado con un aumento del 73% en las probabilidades del pago al corriente (`Fully Paid`)
- Si la variable `Purpose` adopta el valor `educational expenses`, este evento estara asociado con un aumento del 29% en las probabilidades del pago al corriente (`Fully Paid`)
- Si la variable `Purpose` adopta el valor `house improvement`, este evento estara asociado con un aumento del 115% en las probabilidades del pago al corriente (`Fully Paid`)
- Si la variable `Purpose` adopta el valor `major_purchase`, este evento estara asociado con un aumento del 16% en las probabilidades del pago al corriente (`Fully Paid`)
- Si la variable `Purpose` adopta el valor `medical bills`, este evento estara asociado con un aumento del 69% en las probabilidades del pago al corriente (`Fully Paid`)
- Si la variable `Purpose` adopta el valor `moving`, este evento estara asociado con un aumento del 22% en las probabilidades del pago al corriente (`Fully Paid`)
- Si la variable `Purpose` adopta el valor `other`, este evento estara asociado con un aumento del 81% en las probabilidades del pago al corriente (`Fully Paid`)
- Si la variable `Purpose` adopta el valor `renewable_energy`, este evento estara asociado con un aumento muy exagerado en las probabilidades del pago al corriente (`Fully Paid`)
- Si la variable `Purpose` adopta el valor `small_business`, este evento estara asociado con una disminución del 57% en las probabilidades del pago al corriente (`Fully Paid`)
- Si la variable `Purpose` adopta el valor `take a trip`, este evento estara asociado con un aumento del 200% en las probabilidades del pago al corriente (`Fully Paid`)
- Si la variable `Purpose` adopta el valor `vacation`, este evento estara asociado con un aumento del 200% en las probabilidades del pago al corriente (`Fully Paid`)
- Si la variable `Purpose` adopta el valor `wedding`, este evento estara asociado con una disminución del 3% en las probabilidades del pago al corriente (`Fully Paid`).
- Si la variable `Current.Loan.Amount` aumenta en 10,000,000 unidades, este evento estara asociado con un aumento del 0.77% en las probabilidades del pago al corriente (`Fully Paid`).
- Si la variable `Credit.Score` aumenta en una 100 unidades, este evento estara asociado con una disminución del 13.9% en las probabilidades del pago al corriente (`Fully Paid`).
- Si la variable `Annual.Income` aumenta en 1,000,000 unidades, este evento estara asociado con un aumento del 32% en las probabilidades del pago al corriente (`Fully Paid`).
- Si la variable `Monthly.Debt` aumenta en 10,00 unidades, este evento estara asociado con una disminución del 11.9% en las probabilidades del pago al corriente (`Fully Paid`).
- Si la variable `Years.of.Credit.History` aumenta en una unidad, este evento estara asociado con un aumento del 1% en las probabilidades del pago al corriente (`Fully Paid`).

De lo que podemos concluir que las variables con mayor incidencia son:
- la variable nominal `Purpose` con el valor `buy a car`.
- la variable nominal `Purpose` con el valor `take a trip`.
- la variable nominal `Purpose` con el valor `home improvements`.

###### Evaluación supuestos

- VIF (Ausencia de multicolinealidad)

```{r, echo=FALSE}
#vif(modelo_1_2)
vif_modelo <- vif(modelo_1_2)
datos_vif <- data.frame(VIF = vif_modelo)
ggplot(datos_vif, aes(x = row.names(datos_vif), y = VIF.GVIF)) +
  geom_bar(stat = "identity", fill = "blue", width = 0.5) +
  coord_flip() +
  ggtitle("Valores de VIF para cada variable del modelo") +
  xlab("Variables del modelo") +
  ylab("Valor de VIF")
#Ordenar de menor a mayor
```

Gráfica no. 7 (VIF modelo 1.2)-

- La variable de interés es de respuesta binaria.
Este supuesto se corrobora al inicio de este rmarkdown.
- Las variables independientes estan relacionadas linealmente con la variable dependiente.
Este supuesto se corroboró en el EDA.


###### Bootstraping del modelo 1.2


Empleamos como estadístico a evalua el % de aciertos (suma de verdaderos positivos y verdaderos negativos sobre el numero de observaciones en Train para este caso)


```{r}
modelo.fun <- function(datos, subconjunto){
  #Generamos un vector de Predicción para la probabilidad de fully charged (1) para un nuevo vector random [llamado predicciones]
  predicciones<-predict(modelo_1_2, newdata = datos[subconjunto,])
  #Con dicho vector [predicciones], separar por clases para fully paid (1) y charged off(0) para generar el nuevo vector [Prediccion]
  Predicciones <- as.factor(ifelse(predicciones >= Corte_1[corte_optimo_1][1],
                                yes = 1, no = 0))
  # Instanciamos la matriz de confusion para la variable de respuesta       (loan.status) con el vector de probabilidades llamado predicciones
  cfmtx = confusionMatrix(data = as.factor(datos$Loan.Status), 
                             Predicciones)
  
  # Generamos un promedio de el porcentaje de aciertos general
  class_prop = (cfmtx$table[1] + cfmtx$table[4]) / length(Train_intern_1$Loan.Status)
  
  
  # Regresamos dicho promedio
  return(class_prop)
}


Bootstrap<-boot(data = Train_intern_1, 
                statistic = modelo.fun,## <- el parámetro 
                #### statistic requiere una función que reciba dos 
                #### parámetros: la muestra y los índices
                R = 10000) #10mil muestras simuladas

Bootstrap
```

Salida de consola y código no. 17 (Bootstraping en el modelo no 1.2)-


```{r}
mean = mean(Bootstrap$t[,1])
bootstrap_vector_modelo_1_2 = Bootstrap$t[,1]

hist(Bootstrap$t[,1], breaks = 100,
     xlab = "% de aciertos",
     main = "Bootstrap de la predicción para el modelo 1.2",
     ylab = "Frecuencia")
abline(v = quantile(x = Bootstrap$t[,1], c(.025,.975)),col = "red")
abline(v = mean(Bootstrap$t[,1]), col = "darkgreen", lwd = 2)
text(x=.758, y=300, labels = glue("Promedio \n{round(mean, 4)}"))
```

Gráfica no. 8 (Bootstraping en el modelo 1.2)-

##### Modelo no 1.3

- Respuesta del modelo en el conjunto de prueba

```{r, echo=FALSE}
prediccion_3 = predict(object = modelo_1_3,
                    newdata = Test_intern_1, type = "response")
boxplot(prediccion_3)
```
Gráfica no. 9 (Distribución de la predicción para el modelo no 1.3)-

- punto de corte ideal para maximizar la sensibilidad (vs Test)

```{r}
prediccion_3 = predict(object = modelo_1_3,
                    newdata = Test_intern_1, type = "response")

Exactitud_1 <- vector()
Corte_1 <- seq(0.05, 0.95, by = 0.001)

for (i in 1:length(Corte_1)) {
  Prediccion <- as.factor(ifelse(prediccion_3 >= Corte_1[i], yes = 1, no = 0))
  
  Exactitud_1[i] <- tryCatch(
    {
      # confusionMatrix(data = as.factor(Test_intern_1$Loan.Status), Prediccion)$overall[1]
      confusionMatrix(data = as.factor(Test_intern_1$Loan.Status), 
                             Prediccion)$byClass[1]
    },
    error = function(e) {
      0 # O cualquier valor predeterminado
    }
  )
}

plot(x=Corte_1, y = Exactitud_1, type = "l", main ="Punto de corte óptimo para maximizar la sensibilidad (vs Test)", xlab="Corte", ylab="Exactitud")
```
Gráfica no. 10 (punto de corte ideal para maximizar la sensibilidad (vs Test) en modelo no 1.3)-

- punto de corte ideal para maximizar la sensibilidad (vs Test)

```{r}
prediccion_3 = predict(object = modelo_1_3,
                    newdata = Test_intern_1, type = "response")

Exactitud_1 <- vector()
Corte_1 <- seq(0.05, 0.95, by = 0.001)

for (i in 1:length(Corte_1)) {
  Prediccion <- as.factor(ifelse(prediccion_3 >= Corte_1[i], yes = 1, no = 0))
  
  Exactitud_1[i] <- tryCatch(
    {
      # confusionMatrix(data = as.factor(Test_intern_1$Loan.Status), Prediccion)$overall[1]
      confusionMatrix(data = as.factor(Test_intern_1$Loan.Status), 
                             Prediccion)$byClass[2]
    },
    error = function(e) {
      0 # O cualquier valor predeterminado
    }
  )
}

plot(x=Corte_1, y = Exactitud_1, type = "l", main ="Punto de corte óptimo para maximizar la especificidad (vs Test)", xlab="Corte", ylab="Exactitud")
```

Gráfica no. 11 (punto de corte ideal para maximizar la especificidad (vs Test) en modelo no 1.3)-


- punto de corte ideal para maximizar la exactitud (vs Test)

```{r}

prediccion_3 = predict(object = modelo_1_3,
                    newdata = Test_intern_1, type = "response")

Exactitud_1 <- vector()
Corte_1 <- seq(0.05, 0.95, by = 0.001)

for (i in 1:length(Corte_1)) {
  Prediccion <- as.factor(ifelse(prediccion_3 >= Corte_1[i], yes = 1, no = 0))
  
  Exactitud_1[i] <- tryCatch(
    {
      confusionMatrix(data = as.factor(Test_intern_1$Loan.Status), Prediccion)$overall[1]
    },
    error = function(e) {
      0 # O cualquier valor predeterminado
    }
  )
}

plot(x=Corte_1, y = Exactitud_1, type = "l", main ="Punto de corte óptimo para maximizar la exactitud (vs Test)", xlab="Corte", ylab="Exactitud")
```
Gráfica no. 12 (punto de corte ideal para maximizar la exactitud (vs Test) en modelo no 1.3)-

```{r}
corte_optimo_1 = which(Exactitud_1==max(Exactitud_1))
Corte_1[corte_optimo_1][1]
```
Salida de consola y código no. 18 (Corte ótimo para máximizar la exactitud en modelo no 1.3)-

###### Matriz de confusión para el modelo 1.3

```{r}
Prediccion_3<-as.factor(ifelse(prediccion_3>=Corte_1[corte_optimo_1][1],yes = 1, no = 0))

confusionMatrix(data = as.factor(Test_intern_1$Loan.Status), 
                             Prediccion_3)

cfmx3 = confusionMatrix(data = as.factor(Test_intern_1$Loan.Status), 
                             Prediccion_3)
```
Salida de consola y código no. 19 (Matriz de confusión para el modelo no 1.3)-

```{r}
mosaic(cfmx3$table, shade = T, colorize = T,
       gp = gpar(fill = matrix(c("green3", "red2", "red2", "green3"), 2, 2)),
       main = "Matriz de confusión")
```
Salida de consola y código no. 20 (Matriz de confusión ilustrada para el modelo no 1.3)-

###### Curva ROC

```{r}
##### Comparar modelo ya ajustado (no.1) con uno nuevo y muy simple
Prediccion_3_roc<-predict(object = modelo_1_3,
                    newdata = Test_intern_1, type = "response", 
                    se.fit = T)

predicciones_roc_3=prediction(Prediccion_3_roc$fit,Test_intern_1$Loan.Status)
Desempeno_roc_3<-performance(predicciones_roc_3,'tpr','fpr')

#ejecutar en conjunto
plot(Desempeno_roc_3,col="darkgreen")
plot(Desempeno1_prueba, col = "firebrick", add = T)
```
Gráfica no. 13 (Curva ROC modelo 1.2)-

######  Identificando los coeficientes modelo no.2

```{r, echo=FALSE}
nombres_vars = names(coef(modelo_1_3))
resumen = summary(modelo_1_3)

# Iterar por cada variable e imprimir su nombre y coeficiente
for (i in seq_along(nombres_vars)) {
  cat(paste(nombres_vars[i], ": ", resumen$coefficients[i, "Estimate"], "\n"))
}
```
Salida de consola y código no. 21 (Coeficientes modelo no 1.3)-

###### Intervalos de confianza modelo no.3

```{r, echo=FALSE}
confint(object = modelo_1_3, level = 0.95)
```
Salida de consola y código no. 22 (Intervalos de confianza para el modelo no 1.3)-

######  ODDS Ratios del modelo no 1.3
- Identificando los odds ratios 
$e^{B_{k}}$

```{r, echo=FALSE}
nombres_vars = names(coef(modelo_1_3))
resumen = summary(modelo_1_3)

# Iterar por cada variable e imprimir su nombre y el num de euler elevado al coeficiente
for (i in seq_along(nombres_vars)) {
  cat(paste(nombres_vars[i], ": ", exp(resumen$coefficients[i, "Estimate"]), "\n"))
}
```
Salida de consola y código no. 23 (Odds ratios para el modelo no 1.3)-

######  Interpretación Odds ratios en el modelo no 1.3

- Si la variable `Term` adopta el valor `Short`, este evento estara asociado con un aumento del 69% en las probabilidades del pago al corriente (`Fully Paid`) comparado con el evento cuando `Term` adopa el valor de `Long`.
- Si la variable `Years.in.current.job` adopta el valor `1 year`, este evento estara asociado con un 29% en las probabilidades del pago al corriente (`Fully Paid`).
- Si la variable `Years.in.current.job` adopta el valor `10+ years`, este evento estara asociado con un 24.9% en las probabilidades del pago al corriente (`Fully Paid`).
- Si la variable `Years.in.current.job` adopta el valor `2 years`, este evento estara asociado con un 7% en las probabilidades del pago al corriente (`Fully Paid`).
- Si la variable `Years.in.current.job` adopta el valor `3 years`, este evento estara asociado con un 28.9% en las probabilidades del pago al corriente (`Fully Paid`).
- Si la variable `Years.in.current.job` adopta el valor `4 years`, este evento estara asociado con un 17.7 en las probabilidades del pago al corriente (`Fully Paid`).
- Si la variable `Years.in.current.job` adopta el valor `5 years`, este evento estara asociado con un 22.4% en las probabilidades del pago al corriente (`Fully Paid`).
- Si la variable `Years.in.current.job` adopta el valor `6 years`, este evento estara asociado con un 1% en las probabilidades del pago al corriente (`Fully Paid`).
- Si la variable `Years.in.current.job` adopta el valor `7 year`, este evento estara asociado con un 12.2% en las probabilidades del pago al corriente (`Fully Paid`).
- Si la variable `Years.in.current.job` adopta el valor `8 year`, este evento estara asociado con un 11% en las probabilidades del pago al corriente (`Fully Paid`).
- Si la variable `Years.in.current.job` adopta el valor `9 year`, este evento estara asociado con un 39% en las probabilidades del pago al corriente (`Fully Paid`).
- Si la variable `Years.in.current.job` adopta el valor `n/a`, este evento estara asociado con un 0% en las probabilidades del pago al corriente (`Fully Paid`).
- Si la variable `Purpose` adopta el `buy a car`, este evento estara asociado con un aumento del 265% en las probabilidades del pago al corriente (`Fully Paid`)
- Si la variable `Purpose` adopta el `buy a house`, este evento estara asociado con un aumento del 44% en las probabilidades del pago al corriente (`Fully Paid`)
- Si la variable `Purpose` adopta el valor `debt consolidation`, este evento estara asociado con un aumento del 74% en las probabilidades del pago al corriente (`Fully Paid`)
- Si la variable `Purpose` adopta el valor `educational expenses`, este evento estara asociado con un aumento del 30% en las probabilidades del pago al corriente (`Fully Paid`)
- Si la variable `Purpose` adopta el valor `house improvement`, este evento estara asociado con un aumento del 116% en las probabilidades del pago al corriente (`Fully Paid`)
- Si la variable `Purpose` adopta el valor `major_purchase`, este evento estara asociado con un aumento del 15% en las probabilidades del pago al corriente (`Fully Paid`)
- Si la variable `Purpose` adopta el valor `medical bills`, este evento estara asociado con un aumento del 74% en las probabilidades del pago al corriente (`Fully Paid`)
- Si la variable `Purpose` adopta el valor `moving`, este evento estara asociado con un aumento del 20% en las probabilidades del pago al corriente (`Fully Paid`)
- Si la variable `Purpose` adopta el valor `other`, este evento estara asociado con un aumento del 81% en las probabilidades del pago al corriente (`Fully Paid`)
- Si la variable `Purpose` adopta el valor `renewable_energy`, este evento estara asociado con un aumento muy exagerado en las probabilidades del pago al corriente (`Fully Paid`)
- Si la variable `Purpose` adopta el valor `small_business`, este evento estara asociado con una disminución del 58% en las probabilidades del pago al corriente (`Fully Paid`)
- Si la variable `Purpose` adopta el valor `take a trip`, este evento estara asociado con un aumento del 198% en las probabilidades del pago al corriente (`Fully Paid`)
- Si la variable `Purpose` adopta el valor `vacation`, este evento estara asociado con un aumento del 48% en las probabilidades del pago al corriente (`Fully Paid`)
- Si la variable `Purpose` adopta el valor `wedding`, este evento estara asociado con una disminución del 3% en las probabilidades del pago al corriente (`Fully Paid`).
- Si la variable `Current.Loan.Amount` aumenta en 1,000,000 unidades, este evento estara asociado con un aumento del 0.77% en las probabilidades del pago al corriente (`Fully Paid`).
- Si la variable `Credit.Score` aumenta en 100 unidades, este evento estara asociado con una disminución del 13% en las probabilidades del pago al corriente (`Fully Paid`).
- Si la variable `Annual.Income` aumenta en 100,000 unidades, este evento estara asociado con un aumento del 32% en las probabilidades del pago al corriente (`Fully Paid`).
- Si la variable `Monthly.Debt` aumenta en 10,000 unidades, este evento estara asociado con una disminución del 11.8% en las probabilidades del pago al corriente (`Fully Paid`).

De lo que podemos concluir que las variables con mayor incidencia son:
- la variable nominal `Purpose` con el valor `buy a car`.
- la variable nominal `Purpose` con el valor `take a trip`.
- la variable nominal `Purpose` con el valor `home improvements`.

###### Evaluación supuestos

- VIF

```{r, echo=FALSE}
#vif(modelo_1_3)
vif_modelo <- vif(modelo_1_3)
datos_vif <- data.frame(VIF = vif_modelo)
ggplot(datos_vif, aes(x = row.names(datos_vif), y = VIF.GVIF)) +
  geom_bar(stat = "identity", fill = "blue", width = 0.5) +
  coord_flip() +
  ggtitle("Valores de VIF para cada variable del modelo") +
  xlab("Variables del modelo") +
  ylab("Valor de VIF")
```

Gráfica no. 14 (VIF modelo 1.3)-

- No existen problemas de multicolinealidad.
- La variable de interés es de respuesta binaria.
- Las variables independientes estan relacionadas linealmente con la variable dependiente.

- Pendiente

###### Bootstraping del modelo 1.3


Empleamos como estadístico a evalua el % de aciertos (suma de verdaderos positivos y verdaderos negativos sobre el numero de observaciones en Train para este caso)


```{r}
modelo.fun <- function(datos, subconjunto){
  #Generamos un vector de Predicción para la probabilidad de fully charged (1) para un nuevo vector random [llamado predicciones]
  predicciones<-predict(modelo_1_3, newdata = datos[subconjunto,])
  #Con dicho vector [predicciones], separar por clases para fully paid (1) y charged off(0) para generar el nuevo vector [Prediccion]
  Predicciones <- as.factor(ifelse(predicciones >= Corte_1[corte_optimo_1][1],
                                yes = 1, no = 0))
  # Instanciamos la matriz de confusion para la variable de respuesta       (loan.status) con el vector de probabilidades llamado predicciones
  cfmtx = confusionMatrix(data = as.factor(datos$Loan.Status), 
                             Predicciones)
  
  # Generamos un promedio de el porcentaje de aciertos general
  class_prop = (cfmtx$table[1] + cfmtx$table[4]) / length(Train_intern_1$Loan.Status)
  
  
  # Regresamos dicho promedio
  return(class_prop)
}


Bootstrap<-boot(data = Train_intern_1, 
                statistic = modelo.fun,## <- el parámetro 
                #### statistic requiere una función que reciba dos 
                #### parámetros: la muestra y los índices
                R = 10000) #10mil muestras simuladas

Bootstrap
```

Salida de consola y código no. 24 (Bootstraping en el modelo no 1.3)-


```{r}
mean = mean(Bootstrap$t[,1])
bootstrap_vector_modelo_1_3 = Bootstrap$t[,1]

hist(Bootstrap$t[,1], breaks = 100,
     xlab = "% de aciertos",
     main = "Bootstrap de la predicción para el modelo 1.3",
     ylab = "Frecuencia")
abline(v = quantile(x = Bootstrap$t[,1], c(.025,.975)),col = "red")
abline(v = mean(Bootstrap$t[,1]), col = "darkgreen", lwd = 2)
text(x=.758, y=300, labels = glue("Promedio \n {round(mean, 4)}"))
```

Gráfica no. 15 (Bootstraping en el modelo 1.3)-


Comparación de remuestreos en los modelos
```{r, echo=FALSE}
df <- data.frame(datos = c(bootstrap_vector_modelo_1_2, bootstrap_vector_modelo_1_3), 
                 grupo = rep(c("Modelo 1", "Modelo 2"), each = 100))

# Crear la gráfica con ggplot2
ggplot(df, aes(x = datos, fill = grupo)) + 
  geom_histogram(alpha = 0.5, position = "identity", bins = 100) +
  geom_density(aes(color = grupo), size = 1, fill=NA) +
  labs(x = "Valores", y = "Frecuencia") +
  ggtitle("Comparación de remuestreos") +
  scale_color_manual(values = c("darksalmon", "steelblue"))+
  theme_bw()
```

##### Conclusiones Generales

Con base en el estadístico de prueb (% total de aciertos) el mejor modelo a emplear en esta muestra de estudio, con base en el análisis de selección de variables, validación cruzada y remuestreo o bootstraping, resultaría ser el modelo 1.2. Aunque es de mencionar que las diferencias son minimas, por lo que es importante tomar en cuenta los resultados del EDA para la toma de esta desición.

Las conclusiones del EDA nos indican que....




##### Exportando modelo al directorio

```{r}
cfmx_modelo1 = cfmx2
save(modelo_1_2, cfmx_modelo1, file = "../models/Modelo_1.RData")
```

<!-- Se carga tal documento con -->
<!-- load(file = "Ajuste Modelo.RData") -->












