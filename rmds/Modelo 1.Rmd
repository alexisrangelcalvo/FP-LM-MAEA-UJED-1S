---
title: "Modelo 1"
author: "Alexis Rangel"
date: "2023-04-16"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, carga de librerias, include=FALSE, echo=FALSE}
library(tidyverse)
library(gridExtra)
library(glue)
library(caret)
library(ROCR)
library(olsrr)
library(leaps)
library(boot)
library(Amelia)
library(car)
library(RColorBrewer)
library(paletteer)
library(MASS)
library(glmulti) # Automated model selection and model-averaging. (see more here https://rstudio-pubs-static.s3.amazonaws.com/2897_9220b21cfc0c43a396ff9abf122bb351.html)
library(boot)
library(vcd)
```

```{r, carga de datos, include=FALSE}
Train_1 = read.csv("../datasets/muestra_completa.csv")

set.seed(123) # Establecer la semilla para obtener siempre la misma muestra aleatoria
Train_intern_1 <- sample_frac(Train_1, 0.75)
Test_intern_1 <- setdiff(Train_1, Train_intern_1)

# nrow(Train_1)
# nrow(Train_intern_1) + nrow(Test_intern_1) 
```

```{r}
Train_intern_1 = dplyr::select(Train_intern_1, -c(ID))
Test_intern_1 = dplyr::select(Test_intern_1, -c(ID))
#Train_copy_1$Loan.Status = as.factor(Train_copy_1$Loan.Status) 
```



### Modelo de regresión logística.

##### Alcance y objetivo del modelo.

El presente ejercicio se plantea ajustar un modelo que tenga el mejor performance con la muestra completa, con la finalidad de ser evaluado ante la muestra de Test.

##### Ajuste del modelo


- Visualizaciones del modelo de regresion linea simple

```{r}
plot_lrm_1 = ggplot(Train_intern_1, aes(x=Credit.Score, y=Loan.Status)) +
  geom_jitter(height = .02, width = 0, alpha = 0.3) + 
  stat_smooth(method="glm", 
              method.args=list(family="binomial"), se=FALSE)+
  ggtitle("Logit ~Credit.Score")+
  theme_bw()

plot_lrm_2 = ggplot(Train_intern_1, aes(x=Current.Loan.Amount, y=Loan.Status)) +
  geom_jitter(height = .02, width = 0, alpha = 0.3) + 
  stat_smooth(method="glm", 
              method.args=list(family="binomial"), se=FALSE)+
  ggtitle("Logit ~Current.Loan.Amount")+
  theme_bw()

plot_lrm_3 = ggplot(Train_intern_1, aes(x=Annual.Income, y=Loan.Status)) +
  geom_jitter(height = .02, width = 0, alpha = 0.3) + 
  stat_smooth(method="glm", 
              method.args=list(family="binomial"), se=FALSE)+
  ggtitle("Logit ~Annual.Income")+
  theme_bw()

plot_lrm_4 = ggplot(Train_intern_1, aes(x=Monthly.Debt, y=Loan.Status)) +
  geom_jitter(height = .02, width = 0, alpha = 0.3) + 
  stat_smooth(method="glm", 
              method.args=list(family="binomial"), se=FALSE)+
  ggtitle("Logit ~Monthly.Debt")+
  theme_bw()

plot_lrm_5 = ggplot(Train_intern_1, aes(x=Years.of.Credit.History, y=Loan.Status)) +
  geom_jitter(height = .02, width = 0, alpha = 0.3) + 
  stat_smooth(method="glm", 
              method.args=list(family="binomial"), se=FALSE)+
  ggtitle("Logit ~Years.of.Credit.History")+
  theme_bw()

plot_lrm_6 = ggplot(Train_intern_1, aes(x=Months.since.last.delinquent, y=Loan.Status)) +
  geom_jitter(height = .02, width = 0, alpha = 0.3) + 
  stat_smooth(method="glm", 
              method.args=list(family="binomial"), se=FALSE)+
  ggtitle("Logit ~Months.since.last.delinquent")+
  theme_bw()

plot_lrm_7 = ggplot(Train_intern_1, aes(x=Number.of.Open.Accounts, y=Loan.Status)) +
  geom_jitter(height = .02, width = 0, alpha = 0.3) + 
  stat_smooth(method="glm", 
              method.args=list(family="binomial"), se=FALSE)+
  ggtitle("Logit ~Number.of.Open.Accounts")+
  theme_bw()

plot_lrm_8 = ggplot(Train_intern_1, aes(x=Current.Credit.Balance, y=Loan.Status)) +
  geom_jitter(height = .02, width = 0, alpha = 0.3) + 
  stat_smooth(method="glm", 
              method.args=list(family="binomial"), se=FALSE)+
  ggtitle("Logit ~Current.Credit.Balance")+
  theme_bw()

plot_lrm_9 = ggplot(Train_intern_1, aes(x=Maximum.Open.Credit, y=Loan.Status)) +
  geom_jitter(height = .02, width = 0, alpha = 0.3) + 
  stat_smooth(method="glm", 
              method.args=list(family="binomial"), se=FALSE)+
  ggtitle("Logit ~Maximum.Open.Credit")+
  theme_bw()

plot_lrm_10 = ggplot(Train_intern_1, aes(x=Bankruptcies, y=Loan.Status)) +
  geom_jitter(height = .02, width = 0, alpha = 0.3) + 
  stat_smooth(method="glm", 
              method.args=list(family="binomial"), se=FALSE)+
  ggtitle("Logit ~Bankruptcies")+
  theme_bw()

plot_lrm_11 = ggplot(Train_intern_1, aes(x=Tax.Liens, y=Loan.Status)) +
  geom_jitter(height = .02, width = 0, alpha = 0.3) + 
  stat_smooth(method="glm", 
              method.args=list(family="binomial"), se=FALSE)+
  ggtitle("Logit ~Tax.Liens")+
  theme_bw()

grid.arrange(plot_lrm_1, plot_lrm_2, plot_lrm_3, plot_lrm_4, plot_lrm_5, plot_lrm_6, plot_lrm_7, plot_lrm_8, plot_lrm_9, plot_lrm_10, plot_lrm_11, ncol = 4)

```

```{r, include=FALSE, echo=FALSE}
rm(plot_lrm_1, plot_lrm_2, plot_lrm_3, plot_lrm_4, plot_lrm_5, plot_lrm_6, plot_lrm_7, plot_lrm_8, plot_lrm_9, plot_lrm_10, plot_lrm_11)
```


¿Qué se puede concluir del anterior GRID?


######  Ajuste del modelo no. 1




```{r}
modelo_1 = glm(data = Train_intern_1, 
              formula = Loan.Status~., family = "binomial")
summary(modelo_1)
```
######  Update del modelo con las variables estadísticamente significativas
```{r}
modelo_1 = update(object = modelo_1, formula. = .~.-Home.Ownership -Number.of.Open.Accounts -Number.of.Credit.Problems -Current.Credit.Balance -Bankruptcies -Tax.Liens -Months.since.last.delinquent -Maximum.Open.Credit)
summary(modelo_1)
```
El modelo 1 tiene un AIC de 19828, la version que contempla todos los predictores era de 19797
######  Anova del modelo
```{r}
anova(modelo_1)
```


##### Selección de variables en modelo de regresion logistica por críterio de información AIC

```{r}
glmulti.logistic.out <-
    glmulti(Loan.Status ~.-Home.Ownership -Number.of.Open.Accounts -Number.of.Credit.Problems -Current.Credit.Balance -Bankruptcies -Tax.Liens -Months.since.last.delinquent -Maximum.Open.Credit, data = Train_intern_1,
            level = 1,               # No interaction considered
            method = "h",            # Exhaustive approach
            crit = "aic",            # AIC as criteria
            confsetsize = 5,         # Keep 5 best models
            plotty = F, report = F,  # No plot or interim reports
            fitfunction = "glm",     # glm function
            family = binomial)       # binomial family for logistic regression

## Show 5 best models (Use @ instead of $ for an S4 object)
glmulti.logistic.out@formulas
```

```{r}
### CON INTERACCIONES TARDA MUCHISIMO (MÁS DE 1 hora y media Y SIN TERMINAR)
# glmulti.logistic.out <- glmulti(Loan.Status ~.-Home.Ownership -Number.of.Open.Accounts -Number.of.Credit.Problems -Current.Credit.Balance -Bankruptcies -Tax.Liens -Months.since.last.delinquent -Maximum.Open.Credit, data = Train_intern_1,
#                                 level = 2,                   # Considerar interacciones de segundo orden
#                                 method = "h",                # Enfoque exhaustivo
#                                 crit = "aic", # Considerar AIC, BIC y R-squared ajustado
#                                 confsetsize = 5,             # Mantener 5 mejores modelos
#                                 plotty = FALSE,               # Mostrar gráfico
#                                 report = FALSE,              # No informes intermedios
#                                 fitfunction = "glm",         # Función de ajuste glm
#                                 family = binomial)   
```

De entrada, el mejor modelo por AIC que propone la funcion glmulti() es el mismo modelo de regresión logística que se le pasó por parametro, por lo que podemos hablar de que ese al momento es el modelo ideal, con 8 features. Sin embargo en segundo y tercer lugar proponé modelos con 7 features, por lo que se evaluará contra validación cruzada la viabilidad de irnos por un modelo más ligero. 

- Elaborando modelos alternativos a `modelo_1`

```{r}
#Modelo 1.1 que es el mismo modelo_1
modelo_1_1 = glm(data = Train_intern_1, 
              formula = Loan.Status~ Term + Years.in.current.job + Purpose + Current.Loan.Amount + Credit.Score + Annual.Income + Monthly.Debt + Years.of.Credit.History, family = "binomial")

summary(modelo_1_1)
```


El modelo 1.1 tiene un AIC de 19828

- Modelo 1.2
```{r}
#Modelo 1.2
modelo_1_2 = glm(data = Train_intern_1, 
              formula = Loan.Status~ Term + Purpose + Current.Loan.Amount + Credit.Score + Annual.Income + Monthly.Debt + Years.of.Credit.History, family = "binomial")
summary(modelo_1_2)
```
El modelo 1.2 tiene un AIC de 19832

- Modelo 1.3

```{r}
#Modelo 1.3
modelo_1_3 = glm(data = Train_intern_1, 
              formula = Loan.Status~ Term + Years.in.current.job + Purpose + Current.Loan.Amount + Credit.Score + Annual.Income + Monthly.Debt, family = "binomial")
summary(modelo_1_3)
```
El modelo 1.2 tiene un AIC de 19843



##### Validación cruzada y MSPR

De los 5 modelos previamente propuestos por selección de variables con glmulti en regresion logistica y con estadístico AIC, se evaluarán los primeros 3, cada uno por validación cruzada y por MSPR para solo quedarnos con el mejor.

- Validación por k-fold para el modelo base
```{r}
suppressWarnings(MSE_kf_1 <- cv.glm(data = Test_intern_1,
               glmfit = modelo_1, 
               K = 50))
MSE_kf_1$delta
```
Interpretando  `$delta`:

El primer valor representa el error medio cuadrático promedio para los K pliegues (MSPR o Mean Squared Prediction Error), y el segundo valor representa la desviación estándar de los errores medios cuadráticos de los K pliegues.

- Validación por k-fold para el modelo 1.2
```{r}
suppressWarnings(MSE_kf_1_2 <- cv.glm(data = Test_intern_1,
               glmfit = modelo_1_2, 
               K = 50))
MSE_kf_1_2$delta
```

- Validación por k-fold para el modelo 1.3
```{r}
suppressWarnings(MSE_kf_1_3 <- cv.glm(data = Test_intern_1,
               glmfit = modelo_1_3, 
               K = 50))
MSE_kf_1_3$delta
```

Concluimos que la alternativa no.2 con solo 7 features presenta ligeramente un MSPR menor que el modelo base, por lo que dicho modelo junto con el modelo base pasa a la etapa de remuestreo y el estudio de la matriz de confusión con la finalidad de proponer el de mejor performance en estas 2 instancias (validación cruzada donde el modelo 1.2 fue el mejor y matriz de confusión).


##### Modelo no. 1
###### Matriz de confusión para el modelo base con 8 features

- Respuesta del modelo en el conjunto de prueba

```{r}
prediccion_1 = predict(object = modelo_1,
                    newdata = Test_intern_1, type = "response")
boxplot(prediccion_1)
```


- punto de corte ideal para maximizar la sensibilidad (vs Train)

```{r}

prediccion_1 = predict(object = modelo_1,
                    newdata = Train_intern_1, type = "response")

Exactitud_1 <- vector()
Corte_1 <- seq(0.05, 0.95, by = 0.001)

for (i in 1:length(Corte_1)) {
  Prediccion <- as.factor(ifelse(prediccion_1 >= Corte_1[i], yes = 1, no = 0))
  
  Exactitud_1[i] <- tryCatch(
    {
      # confusionMatrix(data = as.factor(Train_intern_1$Loan.Status), Prediccion)$overall[1]
      confusionMatrix(data = as.factor(Train_intern_1$Loan.Status), 
                             Prediccion)$byClass[1]
    },
    error = function(e) {
      0 # O cualquier valor predeterminado
    }
  )
}

plot(x=Corte_1, y = Exactitud_1, type = "l", main ="Punto de corte óptimo para maximizar la sensibilidad (vs Train)", xlab="Corte", ylab="Exactitud")
```

- punto de corte ideal para maximizar la sensibilidad (vs Test)

```{r}

prediccion_1 = predict(object = modelo_1,
                    newdata = Test_intern_1, type = "response")

Exactitud_1 <- vector()
Corte_1 <- seq(0.05, 0.95, by = 0.001)

for (i in 1:length(Corte_1)) {
  Prediccion <- as.factor(ifelse(prediccion_1 >= Corte_1[i], yes = 1, no = 0))
  
  Exactitud_1[i] <- tryCatch(
    {
      # confusionMatrix(data = as.factor(Test_intern_1$Loan.Status), Prediccion)$overall[1]
      confusionMatrix(data = as.factor(Test_intern_1$Loan.Status), 
                             Prediccion)$byClass[1]
    },
    error = function(e) {
      0 # O cualquier valor predeterminado
    }
  )
}

plot(x=Corte_1, y = Exactitud_1, type = "l", main ="Punto de corte óptimo para maximizar la sensibilidad (vs Test)", xlab="Corte", ylab="Exactitud")
```

- punto de corte ideal para maximizar la especificidad (vs Train)

```{r}

prediccion_1 = predict(object = modelo_1,
                    newdata = Train_intern_1, type = "response")

Exactitud_1 <- vector()
Corte_1 <- seq(0.05, 0.95, by = 0.001)

for (i in 1:length(Corte_1)) {
  Prediccion <- as.factor(ifelse(prediccion_1 >= Corte_1[i], yes = 1, no = 0))
  
  Exactitud_1[i] <- tryCatch(
    {
      # confusionMatrix(data = as.factor(Train_intern_1$Loan.Status), Prediccion)$overall[1]
      confusionMatrix(data = as.factor(Train_intern_1$Loan.Status), 
                             Prediccion)$byClass[2]
    },
    error = function(e) {
      0 # O cualquier valor predeterminado
    }
  )
}

plot(x=Corte_1, y = Exactitud_1, type = "l", main ="Punto de corte óptimo para maximizar la especificidad (vs Train)", xlab="Corte", ylab="Exactitud")
```

- punto de corte ideal para maximizar la especificidad (vs Test)

```{r}

prediccion_1 = predict(object = modelo_1,
                    newdata = Test_intern_1, type = "response")

Exactitud_1 <- vector()
Corte_1 <- seq(0.05, 0.95, by = 0.001)

for (i in 1:length(Corte_1)) {
  Prediccion <- as.factor(ifelse(prediccion_1 >= Corte_1[i], yes = 1, no = 0))
  
  Exactitud_1[i] <- tryCatch(
    {
      # confusionMatrix(data = as.factor(Test_intern_1$Loan.Status), Prediccion)$overall[1]
      confusionMatrix(data = as.factor(Test_intern_1$Loan.Status), 
                             Prediccion)$byClass[2]
    },
    error = function(e) {
      0 # O cualquier valor predeterminado
    }
  )
}

plot(x=Corte_1, y = Exactitud_1, type = "l", main ="Punto de corte óptimo para maximizar la especificidad (vs Test)", xlab="Corte", ylab="Exactitud")
```


- punto de corte ideal para maximizar el accuracy (vs Train)

```{r}

prediccion_1 = predict(object = modelo_1,
                    newdata = Train_intern_1, type = "response")

Exactitud_1 <- vector()
Corte_1 <- seq(0.05, 0.95, by = 0.001)

for (i in 1:length(Corte_1)) {
  Prediccion <- as.factor(ifelse(prediccion_1 >= Corte_1[i], yes = 1, no = 0))
  
  Exactitud_1[i] <- tryCatch(
    {
      confusionMatrix(data = as.factor(Train_intern_1$Loan.Status), Prediccion)$overall[1]
    },
    error = function(e) {
      0 # O cualquier valor predeterminado
    }
  )
}

plot(x=Corte_1, y = Exactitud_1, type = "l", main ="Punto de corte óptimo para maximizar el accuracy (vs Train)", xlab="Corte", ylab="Exactitud")
```

- punto de corte ideal para maximizar el accuracy (vs Test)

```{r}

prediccion_1 = predict(object = modelo_1,
                    newdata = Test_intern_1, type = "response")

Exactitud_1 <- vector()
Corte_1 <- seq(0.05, 0.95, by = 0.001)

for (i in 1:length(Corte_1)) {
  Prediccion <- as.factor(ifelse(prediccion_1 >= Corte_1[i], yes = 1, no = 0))
  
  Exactitud_1[i] <- tryCatch(
    {
      confusionMatrix(data = as.factor(Test_intern_1$Loan.Status), Prediccion)$overall[1]
    },
    error = function(e) {
      0 # O cualquier valor predeterminado
    }
  )
}

plot(x=Corte_1, y = Exactitud_1, type = "l", main ="Punto de corte óptimo para maximizar el accuracy (vs Test)", xlab="Corte", ylab="Exactitud")
```

```{r}
corte_optimo_1 = which(Exactitud_1==max(Exactitud_1))
Corte_1[corte_optimo_1]
```
```{r}
Prediccion_1<-as.factor(ifelse(prediccion_1>=Corte_1[corte_optimo_1][1],yes = 1, no = 0))
confusionMatrix(data = as.factor(Test_intern_1$Loan.Status), 
                             Prediccion_1)
cfmx1 = confusionMatrix(data = as.factor(Test_intern_1$Loan.Status), 
                             Prediccion_1)
```

```{r}
mosaic(cfmx1$table, shade = T, colorize = T,
       gp = gpar(fill = matrix(c("green3", "red2", "red2", "green3"), 2, 2)),
       main = "Matriz de confusión")
```


###### Curva ROC

```{r}
##### Comparar modelo ya ajustado (no.1) con uno nuevo y muy simple
Prediccion_1_roc<-predict(object = modelo_1,
                    newdata = Test_intern_1, type = "response", 
                    se.fit = T)

predicciones_roc_1=prediction(Prediccion_1_roc$fit,Test_intern_1$Loan.Status)
Desempeno_roc_1<-performance(predicciones_roc_1,'tpr','fpr')

## Cgenerando nuevo modelo simple
modelo_simple_prueba <- glm(data = Train_intern_1, 
              formula = Loan.Status~Purpose+Bankruptcies, family = "binomial")

Prediccion_1_prueba<-predict(object = modelo_simple_prueba,
                    newdata = Test_intern_1, type = "response", 
                    se.fit = T)

predicciones1_prueba<-prediction(Prediccion_1_prueba$fit,Test_intern_1$Loan.Status)
Desempeno1_prueba<-performance(predicciones1_prueba,'tpr','fpr')

plot(Desempeno_roc_1,col="darkgreen")
plot(Desempeno1_prueba, col = "firebrick", add = T)

legend(x=.6, y=.4, legend = c("Completo","Simple"),
      lwd = 2, col = c("darkgreen", "firebrick"),
      title = "Modelos")
```



###### Intervalos de confianza modelo no.1

```{r}
confint(object = modelo_1, level = 0.95)
```

######  Identificando los coeficientes modelo no.1

```{r}
nombres_vars = names(coef(modelo_1))
resumen = summary(modelo_1)

# Iterar por cada variable e imprimir su nombre y coeficiente
for (i in seq_along(nombres_vars)) {
  cat(paste(nombres_vars[i], ": ", resumen$coefficients[i, "Estimate"], "\n"))
}
```

######  ODDS Ratios del modelo no.1
- Identificando los odds ratios 
$e^{B_{k}}$

```{r}
nombres_vars = names(coef(modelo_1))
resumen = summary(modelo_1)

# Iterar por cada variable e imprimir su nombre y el num de euler elevado al coeficiente
for (i in seq_along(nombres_vars)) {
  cat(paste(nombres_vars[i], ": ", exp(resumen$coefficients[i, "Estimate"]), "\n"))
}
```




###### Bootstrap




##### Modelo no. 2
###### Matriz de confusión para el modelo base con 7 features

- Respuesta del modelo en el conjunto de prueba

```{r}
prediccion_2 = predict(object = modelo_1_2,
                    newdata = Test_intern_1, type = "response")
boxplot(prediccion_2)
```
Parece que hay que ajustar el modelo por la distribución que muestra.

- punto de corte ideal para maximizar la sensibilidad (vs Train)

```{r}

prediccion_2 = predict(object = modelo_1_2,
                    newdata = Train_intern_1, type = "response")

Exactitud_1 <- vector()
Corte_1 <- seq(0.05, 0.95, by = 0.001)

for (i in 1:length(Corte_1)) {
  Prediccion <- as.factor(ifelse(prediccion_2 >= Corte_1[i], yes = 1, no = 0))
  
  Exactitud_1[i] <- tryCatch(
    {
      # confusionMatrix(data = as.factor(Train_intern_1$Loan.Status), Prediccion)$overall[1]
      confusionMatrix(data = as.factor(Train_intern_1$Loan.Status), 
                             Prediccion)$byClass[1]
    },
    error = function(e) {
      0 # O cualquier valor predeterminado
    }
  )
}

plot(x=Corte_1, y = Exactitud_1, type = "l", main ="Punto de corte óptimo para maximizar la sensibilidad (vs Train)", xlab="Corte", ylab="Exactitud")
```
- punto de corte ideal para maximizar la sensibilidad (vs Test)

```{r}

prediccion_2 = predict(object = modelo_1_2,
                    newdata = Test_intern_1, type = "response")

Exactitud_1 <- vector()
Corte_1 <- seq(0.05, 0.95, by = 0.001)

for (i in 1:length(Corte_1)) {
  Prediccion <- as.factor(ifelse(prediccion_2 >= Corte_1[i], yes = 1, no = 0))
  
  Exactitud_1[i] <- tryCatch(
    {
      # confusionMatrix(data = as.factor(Test_intern_1$Loan.Status), Prediccion)$overall[1]
      confusionMatrix(data = as.factor(Test_intern_1$Loan.Status), 
                             Prediccion)$byClass[1]
    },
    error = function(e) {
      0 # O cualquier valor predeterminado
    }
  )
}

plot(x=Corte_1, y = Exactitud_1, type = "l", main ="Punto de corte óptimo para maximizar la sensibilidad (vs Test)", xlab="Corte", ylab="Exactitud")
```

- punto de corte ideal para maximizar el accuracy (vs Train)

```{r}

prediccion_2 = predict(object = modelo_1_2,
                    newdata = Train_intern_1, type = "response")

Exactitud_1 <- vector()
Corte_1 <- seq(0.05, 0.95, by = 0.001)

for (i in 1:length(Corte_1)) {
  Prediccion <- as.factor(ifelse(prediccion_2 >= Corte_1[i], yes = 1, no = 0))
  
  Exactitud_1[i] <- tryCatch(
    {
      confusionMatrix(data = as.factor(Train_intern_1$Loan.Status), Prediccion)$overall[1]
    },
    error = function(e) {
      0 # O cualquier valor predeterminado
    }
  )
}

plot(x=Corte_1, y = Exactitud_1, type = "l", main ="Punto de corte óptimo para maximizar el accuracy (vs Train)", xlab="Corte", ylab="Exactitud")
```

- punto de corte ideal para maximizar el accuracy (vs Test)

```{r}

prediccion_2 = predict(object = modelo_1_2,
                    newdata = Test_intern_1, type = "response")

Exactitud_1 <- vector()
Corte_1 <- seq(0.05, 0.95, by = 0.001)

for (i in 1:length(Corte_1)) {
  Prediccion <- as.factor(ifelse(prediccion_2 >= Corte_1[i], yes = 1, no = 0))
  
  Exactitud_1[i] <- tryCatch(
    {
      confusionMatrix(data = as.factor(Test_intern_1$Loan.Status), Prediccion)$overall[1]
    },
    error = function(e) {
      0 # O cualquier valor predeterminado
    }
  )
}

plot(x=Corte_1, y = Exactitud_1, type = "l", main ="Punto de corte óptimo para maximizar el accuracy (vs Test)", xlab="Corte", ylab="Exactitud")
```


```{r}
corte_optimo_1 = which(Exactitud_1==max(Exactitud_1))
Corte_1[corte_optimo_1]
```

```{r}
Prediccion_2<-as.factor(ifelse(prediccion_2>=Corte_1[corte_optimo_1][1],yes = 1, no = 0))

confusionMatrix(data = as.factor(Test_intern_1$Loan.Status), 
                             Prediccion_2)

cfmx2 = confusionMatrix(data = as.factor(Test_intern_1$Loan.Status), 
                             Prediccion_2)
```


```{r}
mosaic(cfmx2$table, shade = T, colorize = T,
       gp = gpar(fill = matrix(c("green3", "red2", "red2", "green3"), 2, 2)),
       main = "Matriz de confusión")
```


###### Curva ROC

```{r}
##### Comparar modelo ya ajustado (no.1) con uno nuevo y muy simple
Prediccion_2_roc<-predict(object = modelo_1_2,
                    newdata = Test_intern_1, type = "response", 
                    se.fit = T)

predicciones_roc_2=prediction(Prediccion_2_roc$fit,Test_intern_1$Loan.Status)
Desempeno_roc_2<-performance(predicciones_roc_2,'tpr','fpr')

#ejecutar en conjunto
plot(Desempeno_roc_2,col="darkgreen")
plot(Desempeno1_prueba, col = "firebrick", add = T)
```



###### Intervalos de confianza modelo no.2

```{r}
confint(object = modelo_1_2, level = 0.95)
```

######  Identificando los coeficientes modelo no.2

```{r}
nombres_vars = names(coef(modelo_1_2))
resumen = summary(modelo_1_2)

# Iterar por cada variable e imprimir su nombre y coeficiente
for (i in seq_along(nombres_vars)) {
  cat(paste(nombres_vars[i], ": ", resumen$coefficients[i, "Estimate"], "\n"))
}
```

######  ODDS Ratios del modelo no.2
- Identificando los odds ratios 
$e^{B_{k}}$

```{r}
nombres_vars = names(coef(modelo_1_2))
resumen = summary(modelo_1_2)

# Iterar por cada variable e imprimir su nombre y el num de euler elevado al coeficiente
for (i in seq_along(nombres_vars)) {
  cat(paste(nombres_vars[i], ": ", exp(resumen$coefficients[i, "Estimate"]), "\n"))
}
```

##### Conclusiones

Dado que las pruebas con MSPR y accuracy por matriz de confusión fueron tecnicamente similares, decidimos optar por quedarnos con el modelo_1_2 con 7 features porque es un modelo con menos variables. 

Del mejor modelo podemos interpretar de la anterior salida de consola los ODDS ratios que:

- Si la variable `Term` adopta el valor `Short`, este evento estara asociado con un aumento del 68% en las probabilidades del pago al corriente (`Fully Paid`).
- Si la variable `Purpose` adopta el `buy a car`, este evento estara asociado con un aumento del 266% en las probabilidades del pago al corriente (`Fully Paid`)
- Si la variable `Purpose` adopta el `buy a house`, este evento estara asociado con un aumento del 44% en las probabilidades del pago al corriente (`Fully Paid`)
- Si la variable `Purpose` adopta el valor `debt consolidation`, este evento estara asociado con un aumento del 73% en las probabilidades del pago al corriente (`Fully Paid`)
- Si la variable `Purpose` adopta el valor `educational expenses`, este evento estara asociado con un aumento del 29% en las probabilidades del pago al corriente (`Fully Paid`)
- Si la variable `Purpose` adopta el valor `house improvement`, este evento estara asociado con un aumento del 115% en las probabilidades del pago al corriente (`Fully Paid`)
- Si la variable `Purpose` adopta el valor `major_purchase`, este evento estara asociado con un aumento del 16% en las probabilidades del pago al corriente (`Fully Paid`)
- Si la variable `Purpose` adopta el valor `medical bills`, este evento estara asociado con un aumento del 69% en las probabilidades del pago al corriente (`Fully Paid`)
- Si la variable `Purpose` adopta el valor `moving`, este evento estara asociado con un aumento del 22% en las probabilidades del pago al corriente (`Fully Paid`)
- Si la variable `Purpose` adopta el valor `other`, este evento estara asociado con un aumento del 81% en las probabilidades del pago al corriente (`Fully Paid`)
- Si la variable `Purpose` adopta el valor `renewable_energy`, este evento estara asociado con un aumento muy exagerado en las probabilidades del pago al corriente (`Fully Paid`)
- Si la variable `Purpose` adopta el valor `small_business`, este evento estara asociado con una disminución del 57% en las probabilidades del pago al corriente (`Fully Paid`)
- Si la variable `Purpose` adopta el valor `take a trip`, este evento estara asociado con un aumento del 200% en las probabilidades del pago al corriente (`Fully Paid`)
- Si la variable `Purpose` adopta el valor `vacation`, este evento estara asociado con un aumento del 200% en las probabilidades del pago al corriente (`Fully Paid`)
- Si la variable `Purpose` adopta el valor `wedding`, este evento estara asociado con una disminución del 3% en las probabilidades del pago al corriente (`Fully Paid`).
- Si la variable `Current.Loan.Amount` aumenta en 100,000 unidades, este evento estara asociado con un aumento del 0.77% en las probabilidades del pago al corriente (`Fully Paid`).
- Si la variable `Credit.Score` aumenta en una unidad, este evento estara asociado con una disminución del 13% en las probabilidades del pago al corriente (`Fully Paid`).
- Si la variable `Annual.Income` aumenta en 10,000 unidades, este evento estara asociado con un aumento del 32% en las probabilidades del pago al corriente (`Fully Paid`).
- Si la variable `Monthly.Debt` aumenta en 100 unidades, este evento estara asociado con una disminución del 11.9% en las probabilidades del pago al corriente (`Fully Paid`).
- Si la variable `Years.of.Credit.History` aumenta en una unidad, este evento estara asociado con un aumento del 1% en las probabilidades del pago al corriente (`Fully Paid`).

De lo que podemos concluir que las variables con mayor incidencia son:
- la variable nominal `Purpose` con el valor `buy a car`.
- la variable nominal `Purpose` con el valor `take a trip`.
- la variable nominal `Purpose` con el valor `home improvements`.



 

##### Exportando modelo al directorio

```{r}
cfmx_modelo1 = cfmx2
save(modelo_1_2, cfmx_modelo1, file = "../models/Modelo_1.RData")
```

<!-- Se carga tal documento con -->
<!-- load(file = "Ajuste Modelo.RData") -->












